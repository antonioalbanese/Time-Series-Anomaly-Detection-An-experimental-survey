{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antonioalbanese/Time-Series-Anomaly-Detection-An-experimental-survey/blob/main/TadGAN/TadGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbQGvmWWN7V7",
        "outputId": "0ee90579-4edc-4fdf-a7c8-8c5fc2e4aa22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TadGAN'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 55 (delta 9), reused 8 (delta 8), pack-reused 42\u001b[K\n",
            "Unpacking objects: 100% (55/55), done.\n",
            "/content/TadGAN\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/arunppsg/TadGAN\n",
        "%cd TadGAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to have nab dataset\n",
        "!git clone https://github.com/antonioalbanese/Time-Series-Anomaly-Detection-An-experimental-survey/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQhJZTICQJan",
        "outputId": "de68ff81-0896-4d9f-ef35-afc14839d7ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Time-Series-Anomaly-Detection-An-experimental-survey'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 120 (delta 15), reused 92 (delta 12), pack-reused 17\u001b[K\n",
            "Receiving objects: 100% (120/120), 1.91 MiB | 22.73 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################################\n",
        "########### FUNCTIONS ############\n",
        "##################################\n",
        "import os\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import model\n",
        "import anomaly_detection\n",
        "\n",
        "# logging.basicConfig(filename='train.log', level=logging.DEBUG)\n",
        "\n",
        "class SignalDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        self.signal_df = pd.read_csv(path)\n",
        "        self.signal_columns = self.make_signal_list()\n",
        "        self.make_rolling_signals()\n",
        "\n",
        "    def make_signal_list(self):\n",
        "        signal_list = list()\n",
        "        for i in range(-50, 50):\n",
        "            signal_list.append('signal'+str(i))\n",
        "        return signal_list\n",
        "\n",
        "    def make_rolling_signals(self):\n",
        "        for i in range(-50, 50):\n",
        "            self.signal_df['signal'+str(i)] = self.signal_df['signal'].shift(i)\n",
        "        self.signal_df = self.signal_df.dropna()\n",
        "        self.signal_df = self.signal_df.reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.signal_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.signal_df.loc[idx]\n",
        "        x = row[self.signal_columns].values.astype(float)\n",
        "        x = torch.from_numpy(x)\n",
        "        return {'signal':x, 'anomaly':row['anomaly']}\n",
        "\n",
        "def critic_x_iteration(sample):\n",
        "    optim_cx.zero_grad()\n",
        "\n",
        "    x = sample['signal'].view(1, batch_size, signal_shape)\n",
        "    valid_x = critic_x(x)\n",
        "    valid_x = torch.squeeze(valid_x)\n",
        "    critic_score_valid_x = torch.mean(torch.ones(valid_x.shape) * valid_x) #Wasserstein Loss\n",
        "\n",
        "    #The sampled z are the anomalous points - points deviating from actual distribution of z (obtained through encoding x)\n",
        "    z = torch.empty(1, batch_size, latent_space_dim).uniform_(0, 1)\n",
        "    x_ = decoder(z)\n",
        "    fake_x = critic_x(x_)\n",
        "    fake_x = torch.squeeze(fake_x)\n",
        "    critic_score_fake_x = torch.mean(torch.ones(fake_x.shape) * fake_x)  #Wasserstein Loss\n",
        "\n",
        "    alpha = torch.rand(x.shape)\n",
        "    ix = Variable(alpha * x + (1 - alpha) * x_) #Random Weighted Average\n",
        "    ix.requires_grad_(True)\n",
        "    v_ix = critic_x(ix)\n",
        "    v_ix.mean().backward()\n",
        "    gradients = ix.grad\n",
        "    #Gradient Penalty Loss\n",
        "    gp_loss = torch.sqrt(torch.sum(torch.square(gradients).view(-1)))\n",
        "\n",
        "    #Critic has to maximize Cx(Valid X) - Cx(Fake X).\n",
        "    #Maximizing the above is same as minimizing the negative.\n",
        "    wl = critic_score_fake_x - critic_score_valid_x\n",
        "    loss = wl + gp_loss\n",
        "    loss.backward()\n",
        "    optim_cx.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def critic_z_iteration(sample):\n",
        "    optim_cz.zero_grad()\n",
        "\n",
        "    x = sample['signal'].view(1, batch_size, signal_shape)\n",
        "    z = encoder(x)\n",
        "    valid_z = critic_z(z)\n",
        "    valid_z = torch.squeeze(valid_z)\n",
        "    critic_score_valid_z = torch.mean(torch.ones(valid_z.shape) * valid_z)\n",
        "\n",
        "    z_ = torch.empty(1, batch_size, latent_space_dim).uniform_(0, 1)\n",
        "    fake_z = critic_z(z_)\n",
        "    fake_z = torch.squeeze(fake_z)\n",
        "    critic_score_fake_z = torch.mean(torch.ones(fake_z.shape) * fake_z) #Wasserstein Loss\n",
        "\n",
        "    wl = critic_score_fake_z - critic_score_valid_z\n",
        "\n",
        "    alpha = torch.rand(z.shape)\n",
        "    iz = Variable(alpha * z + (1 - alpha) * z_) #Random Weighted Average\n",
        "    iz.requires_grad_(True)\n",
        "    v_iz = critic_z(iz)\n",
        "    v_iz.mean().backward()\n",
        "    gradients = iz.grad\n",
        "    gp_loss = torch.sqrt(torch.sum(torch.square(gradients).view(-1)))\n",
        "\n",
        "    loss = wl + gp_loss\n",
        "    loss.backward()\n",
        "    optim_cz.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def encoder_iteration(sample):\n",
        "    optim_enc.zero_grad()\n",
        "\n",
        "    x = sample['signal'].view(1, batch_size, signal_shape)\n",
        "    valid_x = critic_x(x)\n",
        "    valid_x = torch.squeeze(valid_x)\n",
        "    critic_score_valid_x = torch.mean(torch.ones(valid_x.shape) * valid_x) #Wasserstein Loss\n",
        "\n",
        "    z = torch.empty(1, batch_size, latent_space_dim).uniform_(0, 1)\n",
        "    x_ = decoder(z)\n",
        "    fake_x = critic_x(x_)\n",
        "    fake_x = torch.squeeze(fake_x)\n",
        "    critic_score_fake_x = torch.mean(torch.ones(fake_x.shape) * fake_x)\n",
        "\n",
        "    enc_z = encoder(x)\n",
        "    gen_x = decoder(enc_z)\n",
        "\n",
        "    mse = mse_loss(x.float(), gen_x.float())\n",
        "    loss_enc = mse + critic_score_valid_x - critic_score_fake_x\n",
        "    loss_enc.backward(retain_graph=True)\n",
        "    optim_enc.step()\n",
        "\n",
        "    return loss_enc\n",
        "\n",
        "def decoder_iteration(sample):\n",
        "    optim_dec.zero_grad()\n",
        "\n",
        "    x = sample['signal'].view(1, batch_size, signal_shape)\n",
        "    z = encoder(x)\n",
        "    valid_z = critic_z(z)\n",
        "    valid_z = torch.squeeze(valid_z)\n",
        "    critic_score_valid_z = torch.mean(torch.ones(valid_z.shape) * valid_z)\n",
        "\n",
        "    z_ = torch.empty(1, batch_size, latent_space_dim).uniform_(0, 1)\n",
        "    fake_z = critic_z(z_)\n",
        "    fake_z = torch.squeeze(fake_z)\n",
        "    critic_score_fake_z = torch.mean(torch.ones(fake_z.shape) * fake_z)\n",
        "\n",
        "    enc_z = encoder(x)\n",
        "    gen_x = decoder(enc_z)\n",
        "\n",
        "    mse = mse_loss(x.float(), gen_x.float())\n",
        "    loss_dec = mse + critic_score_valid_z - critic_score_fake_z\n",
        "    loss_dec.backward(retain_graph=True)\n",
        "    optim_dec.step()\n",
        "\n",
        "    return loss_dec\n",
        "\n",
        "\n",
        "def train(n_epochs=2000):\n",
        "    # logging.debug('Starting training')\n",
        "    print('Starting training')\n",
        "    cx_epoch_loss = list()\n",
        "    cz_epoch_loss = list()\n",
        "    encoder_epoch_loss = list()\n",
        "    decoder_epoch_loss = list()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print('Epoch {}'.format(epoch))\n",
        "        n_critics = 5\n",
        "\n",
        "        cx_nc_loss = list()\n",
        "        cz_nc_loss = list()\n",
        "\n",
        "        for i in range(n_critics):\n",
        "            cx_loss = list()\n",
        "            cz_loss = list()\n",
        "\n",
        "            for batch, sample in enumerate(train_loader):\n",
        "                loss = critic_x_iteration(sample)\n",
        "                cx_loss.append(loss)\n",
        "\n",
        "                loss = critic_z_iteration(sample)\n",
        "                cz_loss.append(loss)\n",
        "\n",
        "            cx_nc_loss.append(torch.mean(torch.tensor(cx_loss)))\n",
        "            cz_nc_loss.append(torch.mean(torch.tensor(cz_loss)))\n",
        "\n",
        "        print('Critic training done in epoch {}'.format(epoch))\n",
        "        encoder_loss = list()\n",
        "        decoder_loss = list()\n",
        "\n",
        "        for batch, sample in enumerate(train_loader):\n",
        "            enc_loss = encoder_iteration(sample)\n",
        "            dec_loss = decoder_iteration(sample)\n",
        "            encoder_loss.append(enc_loss)\n",
        "            decoder_loss.append(dec_loss)\n",
        "\n",
        "        cx_epoch_loss.append(torch.mean(torch.tensor(cx_nc_loss)))\n",
        "        cz_epoch_loss.append(torch.mean(torch.tensor(cz_nc_loss)))\n",
        "        encoder_epoch_loss.append(torch.mean(torch.tensor(encoder_loss)))\n",
        "        decoder_epoch_loss.append(torch.mean(torch.tensor(decoder_loss)))\n",
        "        print('Encoder decoder training done in epoch {}'.format(epoch))\n",
        "        print('critic x loss {:.3f} critic z loss {:.3f} \\nencoder loss {:.3f} decoder loss {:.3f}\\n'.format(cx_epoch_loss[-1], cz_epoch_loss[-1], encoder_epoch_loss[-1], decoder_epoch_loss[-1]))\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            torch.save(encoder.state_dict(), encoder.encoder_path)\n",
        "            torch.save(decoder.state_dict(), decoder.decoder_path)\n",
        "            torch.save(critic_x.state_dict(), critic_x.critic_x_path)\n",
        "            torch.save(critic_z.state_dict(), critic_z.critic_z_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "Pp21is8UO2cc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################\n",
        "############## MAIN ##############\n",
        "##################################\n",
        "\n",
        "# The dataset should have a column name as signal containing the signals and a column with name anomaly containing the true labels (used during validation)\n",
        "\n",
        "\n",
        "import json\n",
        "from sklearn import preprocessing\n",
        "base_folder = \"./Time-Series-Anomaly-Detection-An-experimental-survey/NAB/\"\n",
        "file_name = \"artificialWithAnomaly/art_daily_flatmiddle.csv\"\n",
        "label_file = \"combined_windows.json\"\n",
        "with open(base_folder + label_file) as FI:\n",
        "    j_label = json.load(FI)\n",
        "\n",
        "dataset = pd.read_csv(base_folder + file_name)\n",
        "\n",
        "dataset['timestamp'] = pd.to_datetime(dataset['timestamp'])\n",
        "\n",
        "\n",
        "anomalies_span = j_label[file_name]\n",
        "y = np.zeros(len(dataset))\n",
        "for w in anomalies_span:\n",
        "  start = pd.to_datetime(w[0])\n",
        "  end = pd.to_datetime(w[1])\n",
        "  for idx in dataset.index:\n",
        "      if dataset.loc[idx, 'timestamp'] >= start and dataset.loc[idx, 'timestamp'] <= end:\n",
        "          y[idx] = 1.0\n",
        "dataset['anomaly'] = y\n",
        "dataset = dataset.reset_index().drop(columns=['timestamp', 'index'])\n",
        "dataset.columns = ['signal', 'anomaly']\n",
        "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "dataset['signal'] = scaler.fit_transform(np.array(dataset['signal']).reshape(-1,1))\n",
        "\n",
        "\n",
        "#Splitting intro train and test\n",
        "#TODO could be done in a more pythonic way\n",
        "train_len = int(0.7 * dataset.shape[0])\n",
        "dataset[0:train_len].to_csv('train_dataset.csv', index=False)\n",
        "dataset[train_len:].to_csv('test_dataset.csv', index=False)\n",
        "\n",
        "train_dataset = SignalDataset(path='train_dataset.csv')\n",
        "test_dataset = SignalDataset(path='test_dataset.csv')\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "logging.info('Number of train datapoints is {}'.format(len(train_dataset)))\n",
        "logging.info('Number of samples in train dataset {}'.format(len(train_dataset)))\n",
        "\n",
        "lr = 1e-6\n",
        "\n",
        "signal_shape = 100\n",
        "latent_space_dim = 20\n",
        "encoder_path = 'models/encoder.pt'\n",
        "decoder_path = 'models/decoder.pt'\n",
        "critic_x_path = 'models/critic_x.pt'\n",
        "critic_z_path = 'models/critic_z.pt'\n",
        "\n",
        "encoder = model.Encoder(encoder_path, signal_shape)\n",
        "decoder = model.Decoder(decoder_path, signal_shape)\n",
        "critic_x = model.CriticX(critic_x_path, signal_shape)\n",
        "critic_z = model.CriticZ(critic_z_path)\n",
        "\n",
        "mse_loss = torch.nn.MSELoss()\n",
        "\n",
        "optim_enc = optim.Adam(encoder.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optim_dec = optim.Adam(decoder.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optim_cx = optim.Adam(critic_x.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optim_cz = optim.Adam(critic_z.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "train(n_epochs=1000)\n",
        "\n",
        "anomaly_detection.test(test_loader, encoder, decoder, critic_x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TegqO-w5QVmN",
        "outputId": "18667414-1c74-4875-a975-81cec24405d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training\n",
            "Epoch 0\n",
            "Critic training done in epoch 0\n",
            "Encoder decoder training done in epoch 0\n",
            "critic x loss 0.160 critic z loss -0.020 \n",
            "encoder loss 0.197 decoder loss 0.413\n",
            "\n",
            "Epoch 1\n",
            "Critic training done in epoch 1\n",
            "Encoder decoder training done in epoch 1\n",
            "critic x loss 0.148 critic z loss -0.018 \n",
            "encoder loss 0.209 decoder loss 0.414\n",
            "\n",
            "Epoch 2\n",
            "Critic training done in epoch 2\n",
            "Encoder decoder training done in epoch 2\n",
            "critic x loss 0.136 critic z loss -0.026 \n",
            "encoder loss 0.221 decoder loss 0.413\n",
            "\n",
            "Epoch 3\n",
            "Critic training done in epoch 3\n",
            "Encoder decoder training done in epoch 3\n",
            "critic x loss 0.124 critic z loss -0.024 \n",
            "encoder loss 0.232 decoder loss 0.418\n",
            "\n",
            "Epoch 4\n",
            "Critic training done in epoch 4\n",
            "Encoder decoder training done in epoch 4\n",
            "critic x loss 0.112 critic z loss -0.029 \n",
            "encoder loss 0.244 decoder loss 0.419\n",
            "\n",
            "Epoch 5\n",
            "Critic training done in epoch 5\n",
            "Encoder decoder training done in epoch 5\n",
            "critic x loss 0.100 critic z loss -0.027 \n",
            "encoder loss 0.256 decoder loss 0.421\n",
            "\n",
            "Epoch 6\n",
            "Critic training done in epoch 6\n",
            "Encoder decoder training done in epoch 6\n",
            "critic x loss 0.088 critic z loss -0.033 \n",
            "encoder loss 0.268 decoder loss 0.427\n",
            "\n",
            "Epoch 7\n",
            "Critic training done in epoch 7\n",
            "Encoder decoder training done in epoch 7\n",
            "critic x loss 0.076 critic z loss -0.032 \n",
            "encoder loss 0.279 decoder loss 0.427\n",
            "\n",
            "Epoch 8\n",
            "Critic training done in epoch 8\n",
            "Encoder decoder training done in epoch 8\n",
            "critic x loss 0.065 critic z loss -0.032 \n",
            "encoder loss 0.291 decoder loss 0.430\n",
            "\n",
            "Epoch 9\n",
            "Critic training done in epoch 9\n",
            "Encoder decoder training done in epoch 9\n",
            "critic x loss 0.053 critic z loss -0.034 \n",
            "encoder loss 0.303 decoder loss 0.427\n",
            "\n",
            "Epoch 10\n",
            "Critic training done in epoch 10\n",
            "Encoder decoder training done in epoch 10\n",
            "critic x loss 0.041 critic z loss -0.036 \n",
            "encoder loss 0.314 decoder loss 0.437\n",
            "\n",
            "Epoch 11\n",
            "Critic training done in epoch 11\n",
            "Encoder decoder training done in epoch 11\n",
            "critic x loss 0.029 critic z loss -0.040 \n",
            "encoder loss 0.326 decoder loss 0.434\n",
            "\n",
            "Epoch 12\n",
            "Critic training done in epoch 12\n",
            "Encoder decoder training done in epoch 12\n",
            "critic x loss 0.018 critic z loss -0.039 \n",
            "encoder loss 0.338 decoder loss 0.433\n",
            "\n",
            "Epoch 13\n",
            "Critic training done in epoch 13\n",
            "Encoder decoder training done in epoch 13\n",
            "critic x loss 0.006 critic z loss -0.041 \n",
            "encoder loss 0.349 decoder loss 0.437\n",
            "\n",
            "Epoch 14\n",
            "Critic training done in epoch 14\n",
            "Encoder decoder training done in epoch 14\n",
            "critic x loss -0.006 critic z loss -0.042 \n",
            "encoder loss 0.361 decoder loss 0.432\n",
            "\n",
            "Epoch 15\n",
            "Critic training done in epoch 15\n",
            "Encoder decoder training done in epoch 15\n",
            "critic x loss -0.018 critic z loss -0.045 \n",
            "encoder loss 0.373 decoder loss 0.436\n",
            "\n",
            "Epoch 16\n",
            "Critic training done in epoch 16\n",
            "Encoder decoder training done in epoch 16\n",
            "critic x loss -0.029 critic z loss -0.043 \n",
            "encoder loss 0.384 decoder loss 0.434\n",
            "\n",
            "Epoch 17\n",
            "Critic training done in epoch 17\n",
            "Encoder decoder training done in epoch 17\n",
            "critic x loss -0.041 critic z loss -0.050 \n",
            "encoder loss 0.396 decoder loss 0.438\n",
            "\n",
            "Epoch 18\n",
            "Critic training done in epoch 18\n",
            "Encoder decoder training done in epoch 18\n",
            "critic x loss -0.053 critic z loss -0.051 \n",
            "encoder loss 0.408 decoder loss 0.440\n",
            "\n",
            "Epoch 19\n",
            "Critic training done in epoch 19\n",
            "Encoder decoder training done in epoch 19\n",
            "critic x loss -0.065 critic z loss -0.051 \n",
            "encoder loss 0.419 decoder loss 0.445\n",
            "\n",
            "Epoch 20\n",
            "Critic training done in epoch 20\n",
            "Encoder decoder training done in epoch 20\n",
            "critic x loss -0.076 critic z loss -0.050 \n",
            "encoder loss 0.431 decoder loss 0.437\n",
            "\n",
            "Epoch 21\n",
            "Critic training done in epoch 21\n",
            "Encoder decoder training done in epoch 21\n",
            "critic x loss -0.088 critic z loss -0.055 \n",
            "encoder loss 0.443 decoder loss 0.440\n",
            "\n",
            "Epoch 22\n",
            "Critic training done in epoch 22\n",
            "Encoder decoder training done in epoch 22\n",
            "critic x loss -0.100 critic z loss -0.056 \n",
            "encoder loss 0.454 decoder loss 0.447\n",
            "\n",
            "Epoch 23\n",
            "Critic training done in epoch 23\n",
            "Encoder decoder training done in epoch 23\n",
            "critic x loss -0.112 critic z loss -0.057 \n",
            "encoder loss 0.466 decoder loss 0.450\n",
            "\n",
            "Epoch 24\n",
            "Critic training done in epoch 24\n",
            "Encoder decoder training done in epoch 24\n",
            "critic x loss -0.123 critic z loss -0.064 \n",
            "encoder loss 0.478 decoder loss 0.456\n",
            "\n",
            "Epoch 25\n",
            "Critic training done in epoch 25\n",
            "Encoder decoder training done in epoch 25\n",
            "critic x loss -0.135 critic z loss -0.061 \n",
            "encoder loss 0.490 decoder loss 0.446\n",
            "\n",
            "Epoch 26\n",
            "Critic training done in epoch 26\n",
            "Encoder decoder training done in epoch 26\n",
            "critic x loss -0.147 critic z loss -0.062 \n",
            "encoder loss 0.501 decoder loss 0.454\n",
            "\n",
            "Epoch 27\n",
            "Critic training done in epoch 27\n",
            "Encoder decoder training done in epoch 27\n",
            "critic x loss -0.159 critic z loss -0.064 \n",
            "encoder loss 0.513 decoder loss 0.456\n",
            "\n",
            "Epoch 28\n",
            "Critic training done in epoch 28\n",
            "Encoder decoder training done in epoch 28\n",
            "critic x loss -0.170 critic z loss -0.066 \n",
            "encoder loss 0.525 decoder loss 0.460\n",
            "\n",
            "Epoch 29\n",
            "Critic training done in epoch 29\n",
            "Encoder decoder training done in epoch 29\n",
            "critic x loss -0.182 critic z loss -0.065 \n",
            "encoder loss 0.537 decoder loss 0.460\n",
            "\n",
            "Epoch 30\n",
            "Critic training done in epoch 30\n",
            "Encoder decoder training done in epoch 30\n",
            "critic x loss -0.194 critic z loss -0.071 \n",
            "encoder loss 0.549 decoder loss 0.458\n",
            "\n",
            "Epoch 31\n",
            "Critic training done in epoch 31\n",
            "Encoder decoder training done in epoch 31\n",
            "critic x loss -0.206 critic z loss -0.070 \n",
            "encoder loss 0.560 decoder loss 0.466\n",
            "\n",
            "Epoch 32\n",
            "Critic training done in epoch 32\n",
            "Encoder decoder training done in epoch 32\n",
            "critic x loss -0.218 critic z loss -0.077 \n",
            "encoder loss 0.572 decoder loss 0.460\n",
            "\n",
            "Epoch 33\n",
            "Critic training done in epoch 33\n",
            "Encoder decoder training done in epoch 33\n",
            "critic x loss -0.229 critic z loss -0.076 \n",
            "encoder loss 0.584 decoder loss 0.464\n",
            "\n",
            "Epoch 34\n",
            "Critic training done in epoch 34\n",
            "Encoder decoder training done in epoch 34\n",
            "critic x loss -0.241 critic z loss -0.076 \n",
            "encoder loss 0.596 decoder loss 0.467\n",
            "\n",
            "Epoch 35\n",
            "Critic training done in epoch 35\n",
            "Encoder decoder training done in epoch 35\n",
            "critic x loss -0.253 critic z loss -0.079 \n",
            "encoder loss 0.608 decoder loss 0.465\n",
            "\n",
            "Epoch 36\n",
            "Critic training done in epoch 36\n",
            "Encoder decoder training done in epoch 36\n",
            "critic x loss -0.265 critic z loss -0.078 \n",
            "encoder loss 0.619 decoder loss 0.469\n",
            "\n",
            "Epoch 37\n",
            "Critic training done in epoch 37\n",
            "Encoder decoder training done in epoch 37\n",
            "critic x loss -0.276 critic z loss -0.082 \n",
            "encoder loss 0.631 decoder loss 0.473\n",
            "\n",
            "Epoch 38\n",
            "Critic training done in epoch 38\n",
            "Encoder decoder training done in epoch 38\n",
            "critic x loss -0.288 critic z loss -0.082 \n",
            "encoder loss 0.643 decoder loss 0.472\n",
            "\n",
            "Epoch 39\n",
            "Critic training done in epoch 39\n",
            "Encoder decoder training done in epoch 39\n",
            "critic x loss -0.300 critic z loss -0.085 \n",
            "encoder loss 0.655 decoder loss 0.472\n",
            "\n",
            "Epoch 40\n",
            "Critic training done in epoch 40\n",
            "Encoder decoder training done in epoch 40\n",
            "critic x loss -0.312 critic z loss -0.084 \n",
            "encoder loss 0.667 decoder loss 0.476\n",
            "\n",
            "Epoch 41\n",
            "Critic training done in epoch 41\n",
            "Encoder decoder training done in epoch 41\n",
            "critic x loss -0.324 critic z loss -0.087 \n",
            "encoder loss 0.679 decoder loss 0.480\n",
            "\n",
            "Epoch 42\n",
            "Critic training done in epoch 42\n",
            "Encoder decoder training done in epoch 42\n",
            "critic x loss -0.336 critic z loss -0.089 \n",
            "encoder loss 0.691 decoder loss 0.475\n",
            "\n",
            "Epoch 43\n",
            "Critic training done in epoch 43\n",
            "Encoder decoder training done in epoch 43\n",
            "critic x loss -0.347 critic z loss -0.089 \n",
            "encoder loss 0.703 decoder loss 0.482\n",
            "\n",
            "Epoch 44\n",
            "Critic training done in epoch 44\n",
            "Encoder decoder training done in epoch 44\n",
            "critic x loss -0.359 critic z loss -0.092 \n",
            "encoder loss 0.715 decoder loss 0.482\n",
            "\n",
            "Epoch 45\n",
            "Critic training done in epoch 45\n",
            "Encoder decoder training done in epoch 45\n",
            "critic x loss -0.371 critic z loss -0.095 \n",
            "encoder loss 0.726 decoder loss 0.487\n",
            "\n",
            "Epoch 46\n",
            "Critic training done in epoch 46\n",
            "Encoder decoder training done in epoch 46\n",
            "critic x loss -0.383 critic z loss -0.096 \n",
            "encoder loss 0.738 decoder loss 0.489\n",
            "\n",
            "Epoch 47\n",
            "Critic training done in epoch 47\n",
            "Encoder decoder training done in epoch 47\n",
            "critic x loss -0.395 critic z loss -0.099 \n",
            "encoder loss 0.750 decoder loss 0.486\n",
            "\n",
            "Epoch 48\n",
            "Critic training done in epoch 48\n",
            "Encoder decoder training done in epoch 48\n",
            "critic x loss -0.407 critic z loss -0.100 \n",
            "encoder loss 0.762 decoder loss 0.486\n",
            "\n",
            "Epoch 49\n",
            "Critic training done in epoch 49\n",
            "Encoder decoder training done in epoch 49\n",
            "critic x loss -0.419 critic z loss -0.102 \n",
            "encoder loss 0.774 decoder loss 0.494\n",
            "\n",
            "Epoch 50\n",
            "Critic training done in epoch 50\n",
            "Encoder decoder training done in epoch 50\n",
            "critic x loss -0.430 critic z loss -0.101 \n",
            "encoder loss 0.786 decoder loss 0.490\n",
            "\n",
            "Epoch 51\n",
            "Critic training done in epoch 51\n",
            "Encoder decoder training done in epoch 51\n",
            "critic x loss -0.442 critic z loss -0.105 \n",
            "encoder loss 0.798 decoder loss 0.495\n",
            "\n",
            "Epoch 52\n",
            "Critic training done in epoch 52\n",
            "Encoder decoder training done in epoch 52\n",
            "critic x loss -0.454 critic z loss -0.109 \n",
            "encoder loss 0.810 decoder loss 0.498\n",
            "\n",
            "Epoch 53\n",
            "Critic training done in epoch 53\n",
            "Encoder decoder training done in epoch 53\n",
            "critic x loss -0.466 critic z loss -0.109 \n",
            "encoder loss 0.822 decoder loss 0.498\n",
            "\n",
            "Epoch 54\n",
            "Critic training done in epoch 54\n",
            "Encoder decoder training done in epoch 54\n",
            "critic x loss -0.478 critic z loss -0.110 \n",
            "encoder loss 0.834 decoder loss 0.494\n",
            "\n",
            "Epoch 55\n",
            "Critic training done in epoch 55\n",
            "Encoder decoder training done in epoch 55\n",
            "critic x loss -0.490 critic z loss -0.110 \n",
            "encoder loss 0.846 decoder loss 0.499\n",
            "\n",
            "Epoch 56\n",
            "Critic training done in epoch 56\n",
            "Encoder decoder training done in epoch 56\n",
            "critic x loss -0.502 critic z loss -0.113 \n",
            "encoder loss 0.858 decoder loss 0.499\n",
            "\n",
            "Epoch 57\n",
            "Critic training done in epoch 57\n",
            "Encoder decoder training done in epoch 57\n",
            "critic x loss -0.514 critic z loss -0.117 \n",
            "encoder loss 0.870 decoder loss 0.502\n",
            "\n",
            "Epoch 58\n",
            "Critic training done in epoch 58\n",
            "Encoder decoder training done in epoch 58\n",
            "critic x loss -0.526 critic z loss -0.117 \n",
            "encoder loss 0.883 decoder loss 0.504\n",
            "\n",
            "Epoch 59\n",
            "Critic training done in epoch 59\n",
            "Encoder decoder training done in epoch 59\n",
            "critic x loss -0.538 critic z loss -0.116 \n",
            "encoder loss 0.895 decoder loss 0.504\n",
            "\n",
            "Epoch 60\n",
            "Critic training done in epoch 60\n",
            "Encoder decoder training done in epoch 60\n",
            "critic x loss -0.550 critic z loss -0.121 \n",
            "encoder loss 0.907 decoder loss 0.508\n",
            "\n",
            "Epoch 61\n",
            "Critic training done in epoch 61\n",
            "Encoder decoder training done in epoch 61\n",
            "critic x loss -0.562 critic z loss -0.122 \n",
            "encoder loss 0.919 decoder loss 0.513\n",
            "\n",
            "Epoch 62\n",
            "Critic training done in epoch 62\n",
            "Encoder decoder training done in epoch 62\n",
            "critic x loss -0.574 critic z loss -0.125 \n",
            "encoder loss 0.931 decoder loss 0.511\n",
            "\n",
            "Epoch 63\n",
            "Critic training done in epoch 63\n",
            "Encoder decoder training done in epoch 63\n",
            "critic x loss -0.586 critic z loss -0.123 \n",
            "encoder loss 0.943 decoder loss 0.520\n",
            "\n",
            "Epoch 64\n",
            "Critic training done in epoch 64\n",
            "Encoder decoder training done in epoch 64\n",
            "critic x loss -0.598 critic z loss -0.125 \n",
            "encoder loss 0.955 decoder loss 0.509\n",
            "\n",
            "Epoch 65\n",
            "Critic training done in epoch 65\n",
            "Encoder decoder training done in epoch 65\n",
            "critic x loss -0.610 critic z loss -0.127 \n",
            "encoder loss 0.967 decoder loss 0.525\n",
            "\n",
            "Epoch 66\n",
            "Critic training done in epoch 66\n",
            "Encoder decoder training done in epoch 66\n",
            "critic x loss -0.622 critic z loss -0.127 \n",
            "encoder loss 0.980 decoder loss 0.516\n",
            "\n",
            "Epoch 67\n",
            "Critic training done in epoch 67\n",
            "Encoder decoder training done in epoch 67\n",
            "critic x loss -0.634 critic z loss -0.132 \n",
            "encoder loss 0.992 decoder loss 0.518\n",
            "\n",
            "Epoch 68\n",
            "Critic training done in epoch 68\n",
            "Encoder decoder training done in epoch 68\n",
            "critic x loss -0.646 critic z loss -0.135 \n",
            "encoder loss 1.004 decoder loss 0.520\n",
            "\n",
            "Epoch 69\n",
            "Critic training done in epoch 69\n",
            "Encoder decoder training done in epoch 69\n",
            "critic x loss -0.658 critic z loss -0.133 \n",
            "encoder loss 1.016 decoder loss 0.523\n",
            "\n",
            "Epoch 70\n",
            "Critic training done in epoch 70\n",
            "Encoder decoder training done in epoch 70\n",
            "critic x loss -0.670 critic z loss -0.138 \n",
            "encoder loss 1.029 decoder loss 0.519\n",
            "\n",
            "Epoch 71\n",
            "Critic training done in epoch 71\n",
            "Encoder decoder training done in epoch 71\n",
            "critic x loss -0.682 critic z loss -0.137 \n",
            "encoder loss 1.041 decoder loss 0.525\n",
            "\n",
            "Epoch 72\n",
            "Critic training done in epoch 72\n",
            "Encoder decoder training done in epoch 72\n",
            "critic x loss -0.694 critic z loss -0.139 \n",
            "encoder loss 1.053 decoder loss 0.525\n",
            "\n",
            "Epoch 73\n",
            "Critic training done in epoch 73\n",
            "Encoder decoder training done in epoch 73\n",
            "critic x loss -0.706 critic z loss -0.141 \n",
            "encoder loss 1.065 decoder loss 0.534\n",
            "\n",
            "Epoch 74\n",
            "Critic training done in epoch 74\n",
            "Encoder decoder training done in epoch 74\n",
            "critic x loss -0.718 critic z loss -0.142 \n",
            "encoder loss 1.078 decoder loss 0.526\n",
            "\n",
            "Epoch 75\n",
            "Critic training done in epoch 75\n",
            "Encoder decoder training done in epoch 75\n",
            "critic x loss -0.730 critic z loss -0.143 \n",
            "encoder loss 1.090 decoder loss 0.534\n",
            "\n",
            "Epoch 76\n",
            "Critic training done in epoch 76\n",
            "Encoder decoder training done in epoch 76\n",
            "critic x loss -0.742 critic z loss -0.142 \n",
            "encoder loss 1.102 decoder loss 0.530\n",
            "\n",
            "Epoch 77\n",
            "Critic training done in epoch 77\n",
            "Encoder decoder training done in epoch 77\n",
            "critic x loss -0.755 critic z loss -0.150 \n",
            "encoder loss 1.115 decoder loss 0.534\n",
            "\n",
            "Epoch 78\n",
            "Critic training done in epoch 78\n",
            "Encoder decoder training done in epoch 78\n",
            "critic x loss -0.767 critic z loss -0.148 \n",
            "encoder loss 1.127 decoder loss 0.532\n",
            "\n",
            "Epoch 79\n",
            "Critic training done in epoch 79\n",
            "Encoder decoder training done in epoch 79\n",
            "critic x loss -0.779 critic z loss -0.150 \n",
            "encoder loss 1.140 decoder loss 0.535\n",
            "\n",
            "Epoch 80\n",
            "Critic training done in epoch 80\n",
            "Encoder decoder training done in epoch 80\n",
            "critic x loss -0.791 critic z loss -0.151 \n",
            "encoder loss 1.152 decoder loss 0.539\n",
            "\n",
            "Epoch 81\n",
            "Critic training done in epoch 81\n",
            "Encoder decoder training done in epoch 81\n",
            "critic x loss -0.803 critic z loss -0.155 \n",
            "encoder loss 1.164 decoder loss 0.546\n",
            "\n",
            "Epoch 82\n",
            "Critic training done in epoch 82\n",
            "Encoder decoder training done in epoch 82\n",
            "critic x loss -0.816 critic z loss -0.156 \n",
            "encoder loss 1.177 decoder loss 0.546\n",
            "\n",
            "Epoch 83\n",
            "Critic training done in epoch 83\n",
            "Encoder decoder training done in epoch 83\n",
            "critic x loss -0.828 critic z loss -0.159 \n",
            "encoder loss 1.189 decoder loss 0.541\n",
            "\n",
            "Epoch 84\n",
            "Critic training done in epoch 84\n",
            "Encoder decoder training done in epoch 84\n",
            "critic x loss -0.840 critic z loss -0.162 \n",
            "encoder loss 1.202 decoder loss 0.548\n",
            "\n",
            "Epoch 85\n",
            "Critic training done in epoch 85\n",
            "Encoder decoder training done in epoch 85\n",
            "critic x loss -0.852 critic z loss -0.165 \n",
            "encoder loss 1.214 decoder loss 0.549\n",
            "\n",
            "Epoch 86\n",
            "Critic training done in epoch 86\n",
            "Encoder decoder training done in epoch 86\n",
            "critic x loss -0.865 critic z loss -0.161 \n",
            "encoder loss 1.227 decoder loss 0.551\n",
            "\n",
            "Epoch 87\n",
            "Critic training done in epoch 87\n",
            "Encoder decoder training done in epoch 87\n",
            "critic x loss -0.877 critic z loss -0.163 \n",
            "encoder loss 1.239 decoder loss 0.548\n",
            "\n",
            "Epoch 88\n",
            "Critic training done in epoch 88\n",
            "Encoder decoder training done in epoch 88\n",
            "critic x loss -0.889 critic z loss -0.168 \n",
            "encoder loss 1.252 decoder loss 0.555\n",
            "\n",
            "Epoch 89\n",
            "Critic training done in epoch 89\n",
            "Encoder decoder training done in epoch 89\n",
            "critic x loss -0.901 critic z loss -0.166 \n",
            "encoder loss 1.264 decoder loss 0.551\n",
            "\n",
            "Epoch 90\n",
            "Critic training done in epoch 90\n",
            "Encoder decoder training done in epoch 90\n",
            "critic x loss -0.914 critic z loss -0.171 \n",
            "encoder loss 1.277 decoder loss 0.554\n",
            "\n",
            "Epoch 91\n",
            "Critic training done in epoch 91\n",
            "Encoder decoder training done in epoch 91\n",
            "critic x loss -0.926 critic z loss -0.172 \n",
            "encoder loss 1.290 decoder loss 0.559\n",
            "\n",
            "Epoch 92\n",
            "Critic training done in epoch 92\n",
            "Encoder decoder training done in epoch 92\n",
            "critic x loss -0.938 critic z loss -0.172 \n",
            "encoder loss 1.302 decoder loss 0.557\n",
            "\n",
            "Epoch 93\n",
            "Critic training done in epoch 93\n",
            "Encoder decoder training done in epoch 93\n",
            "critic x loss -0.951 critic z loss -0.176 \n",
            "encoder loss 1.315 decoder loss 0.559\n",
            "\n",
            "Epoch 94\n",
            "Critic training done in epoch 94\n",
            "Encoder decoder training done in epoch 94\n",
            "critic x loss -0.963 critic z loss -0.178 \n",
            "encoder loss 1.327 decoder loss 0.557\n",
            "\n",
            "Epoch 95\n",
            "Critic training done in epoch 95\n",
            "Encoder decoder training done in epoch 95\n",
            "critic x loss -0.975 critic z loss -0.177 \n",
            "encoder loss 1.340 decoder loss 0.564\n",
            "\n",
            "Epoch 96\n",
            "Critic training done in epoch 96\n",
            "Encoder decoder training done in epoch 96\n",
            "critic x loss -0.988 critic z loss -0.181 \n",
            "encoder loss 1.353 decoder loss 0.558\n",
            "\n",
            "Epoch 97\n",
            "Critic training done in epoch 97\n",
            "Encoder decoder training done in epoch 97\n",
            "critic x loss -1.000 critic z loss -0.180 \n",
            "encoder loss 1.365 decoder loss 0.567\n",
            "\n",
            "Epoch 98\n",
            "Critic training done in epoch 98\n",
            "Encoder decoder training done in epoch 98\n",
            "critic x loss -1.013 critic z loss -0.180 \n",
            "encoder loss 1.378 decoder loss 0.568\n",
            "\n",
            "Epoch 99\n",
            "Critic training done in epoch 99\n",
            "Encoder decoder training done in epoch 99\n",
            "critic x loss -1.025 critic z loss -0.184 \n",
            "encoder loss 1.391 decoder loss 0.570\n",
            "\n",
            "Epoch 100\n",
            "Critic training done in epoch 100\n",
            "Encoder decoder training done in epoch 100\n",
            "critic x loss -1.037 critic z loss -0.186 \n",
            "encoder loss 1.403 decoder loss 0.567\n",
            "\n",
            "Epoch 101\n",
            "Critic training done in epoch 101\n",
            "Encoder decoder training done in epoch 101\n",
            "critic x loss -1.050 critic z loss -0.188 \n",
            "encoder loss 1.416 decoder loss 0.576\n",
            "\n",
            "Epoch 102\n",
            "Critic training done in epoch 102\n",
            "Encoder decoder training done in epoch 102\n",
            "critic x loss -1.062 critic z loss -0.191 \n",
            "encoder loss 1.429 decoder loss 0.573\n",
            "\n",
            "Epoch 103\n",
            "Critic training done in epoch 103\n",
            "Encoder decoder training done in epoch 103\n",
            "critic x loss -1.075 critic z loss -0.191 \n",
            "encoder loss 1.441 decoder loss 0.572\n",
            "\n",
            "Epoch 104\n",
            "Critic training done in epoch 104\n",
            "Encoder decoder training done in epoch 104\n",
            "critic x loss -1.087 critic z loss -0.195 \n",
            "encoder loss 1.454 decoder loss 0.573\n",
            "\n",
            "Epoch 105\n",
            "Critic training done in epoch 105\n",
            "Encoder decoder training done in epoch 105\n",
            "critic x loss -1.100 critic z loss -0.194 \n",
            "encoder loss 1.467 decoder loss 0.582\n",
            "\n",
            "Epoch 106\n",
            "Critic training done in epoch 106\n",
            "Encoder decoder training done in epoch 106\n",
            "critic x loss -1.112 critic z loss -0.196 \n",
            "encoder loss 1.480 decoder loss 0.585\n",
            "\n",
            "Epoch 107\n",
            "Critic training done in epoch 107\n",
            "Encoder decoder training done in epoch 107\n",
            "critic x loss -1.125 critic z loss -0.195 \n",
            "encoder loss 1.492 decoder loss 0.584\n",
            "\n",
            "Epoch 108\n",
            "Critic training done in epoch 108\n",
            "Encoder decoder training done in epoch 108\n",
            "critic x loss -1.137 critic z loss -0.197 \n",
            "encoder loss 1.505 decoder loss 0.580\n",
            "\n",
            "Epoch 109\n",
            "Critic training done in epoch 109\n",
            "Encoder decoder training done in epoch 109\n",
            "critic x loss -1.150 critic z loss -0.201 \n",
            "encoder loss 1.518 decoder loss 0.585\n",
            "\n",
            "Epoch 110\n",
            "Critic training done in epoch 110\n",
            "Encoder decoder training done in epoch 110\n",
            "critic x loss -1.162 critic z loss -0.204 \n",
            "encoder loss 1.531 decoder loss 0.584\n",
            "\n",
            "Epoch 111\n",
            "Critic training done in epoch 111\n",
            "Encoder decoder training done in epoch 111\n",
            "critic x loss -1.175 critic z loss -0.203 \n",
            "encoder loss 1.543 decoder loss 0.591\n",
            "\n",
            "Epoch 112\n",
            "Critic training done in epoch 112\n",
            "Encoder decoder training done in epoch 112\n",
            "critic x loss -1.187 critic z loss -0.205 \n",
            "encoder loss 1.556 decoder loss 0.594\n",
            "\n",
            "Epoch 113\n",
            "Critic training done in epoch 113\n",
            "Encoder decoder training done in epoch 113\n",
            "critic x loss -1.200 critic z loss -0.204 \n",
            "encoder loss 1.569 decoder loss 0.585\n",
            "\n",
            "Epoch 114\n",
            "Critic training done in epoch 114\n",
            "Encoder decoder training done in epoch 114\n",
            "critic x loss -1.212 critic z loss -0.210 \n",
            "encoder loss 1.582 decoder loss 0.592\n",
            "\n",
            "Epoch 115\n",
            "Critic training done in epoch 115\n",
            "Encoder decoder training done in epoch 115\n",
            "critic x loss -1.225 critic z loss -0.211 \n",
            "encoder loss 1.595 decoder loss 0.599\n",
            "\n",
            "Epoch 116\n",
            "Critic training done in epoch 116\n",
            "Encoder decoder training done in epoch 116\n",
            "critic x loss -1.237 critic z loss -0.216 \n",
            "encoder loss 1.607 decoder loss 0.593\n",
            "\n",
            "Epoch 117\n",
            "Critic training done in epoch 117\n",
            "Encoder decoder training done in epoch 117\n",
            "critic x loss -1.250 critic z loss -0.211 \n",
            "encoder loss 1.620 decoder loss 0.596\n",
            "\n",
            "Epoch 118\n",
            "Critic training done in epoch 118\n",
            "Encoder decoder training done in epoch 118\n",
            "critic x loss -1.262 critic z loss -0.217 \n",
            "encoder loss 1.633 decoder loss 0.601\n",
            "\n",
            "Epoch 119\n",
            "Critic training done in epoch 119\n",
            "Encoder decoder training done in epoch 119\n",
            "critic x loss -1.275 critic z loss -0.219 \n",
            "encoder loss 1.646 decoder loss 0.600\n",
            "\n",
            "Epoch 120\n",
            "Critic training done in epoch 120\n",
            "Encoder decoder training done in epoch 120\n",
            "critic x loss -1.287 critic z loss -0.217 \n",
            "encoder loss 1.659 decoder loss 0.601\n",
            "\n",
            "Epoch 121\n",
            "Critic training done in epoch 121\n",
            "Encoder decoder training done in epoch 121\n",
            "critic x loss -1.300 critic z loss -0.219 \n",
            "encoder loss 1.672 decoder loss 0.605\n",
            "\n",
            "Epoch 122\n",
            "Critic training done in epoch 122\n",
            "Encoder decoder training done in epoch 122\n",
            "critic x loss -1.312 critic z loss -0.223 \n",
            "encoder loss 1.685 decoder loss 0.602\n",
            "\n",
            "Epoch 123\n",
            "Critic training done in epoch 123\n",
            "Encoder decoder training done in epoch 123\n",
            "critic x loss -1.325 critic z loss -0.222 \n",
            "encoder loss 1.698 decoder loss 0.603\n",
            "\n",
            "Epoch 124\n",
            "Critic training done in epoch 124\n",
            "Encoder decoder training done in epoch 124\n",
            "critic x loss -1.338 critic z loss -0.225 \n",
            "encoder loss 1.710 decoder loss 0.613\n",
            "\n",
            "Epoch 125\n",
            "Critic training done in epoch 125\n",
            "Encoder decoder training done in epoch 125\n",
            "critic x loss -1.350 critic z loss -0.224 \n",
            "encoder loss 1.723 decoder loss 0.612\n",
            "\n",
            "Epoch 126\n",
            "Critic training done in epoch 126\n",
            "Encoder decoder training done in epoch 126\n",
            "critic x loss -1.363 critic z loss -0.227 \n",
            "encoder loss 1.736 decoder loss 0.610\n",
            "\n",
            "Epoch 127\n",
            "Critic training done in epoch 127\n",
            "Encoder decoder training done in epoch 127\n",
            "critic x loss -1.375 critic z loss -0.230 \n",
            "encoder loss 1.749 decoder loss 0.611\n",
            "\n",
            "Epoch 128\n",
            "Critic training done in epoch 128\n",
            "Encoder decoder training done in epoch 128\n",
            "critic x loss -1.388 critic z loss -0.230 \n",
            "encoder loss 1.762 decoder loss 0.620\n",
            "\n",
            "Epoch 129\n",
            "Critic training done in epoch 129\n",
            "Encoder decoder training done in epoch 129\n",
            "critic x loss -1.401 critic z loss -0.233 \n",
            "encoder loss 1.775 decoder loss 0.612\n",
            "\n",
            "Epoch 130\n",
            "Critic training done in epoch 130\n",
            "Encoder decoder training done in epoch 130\n",
            "critic x loss -1.413 critic z loss -0.237 \n",
            "encoder loss 1.788 decoder loss 0.620\n",
            "\n",
            "Epoch 131\n",
            "Critic training done in epoch 131\n",
            "Encoder decoder training done in epoch 131\n",
            "critic x loss -1.426 critic z loss -0.236 \n",
            "encoder loss 1.801 decoder loss 0.626\n",
            "\n",
            "Epoch 132\n",
            "Critic training done in epoch 132\n",
            "Encoder decoder training done in epoch 132\n",
            "critic x loss -1.439 critic z loss -0.236 \n",
            "encoder loss 1.814 decoder loss 0.627\n",
            "\n",
            "Epoch 133\n",
            "Critic training done in epoch 133\n",
            "Encoder decoder training done in epoch 133\n",
            "critic x loss -1.451 critic z loss -0.239 \n",
            "encoder loss 1.827 decoder loss 0.621\n",
            "\n",
            "Epoch 134\n",
            "Critic training done in epoch 134\n",
            "Encoder decoder training done in epoch 134\n",
            "critic x loss -1.464 critic z loss -0.240 \n",
            "encoder loss 1.840 decoder loss 0.624\n",
            "\n",
            "Epoch 135\n",
            "Critic training done in epoch 135\n",
            "Encoder decoder training done in epoch 135\n",
            "critic x loss -1.476 critic z loss -0.243 \n",
            "encoder loss 1.853 decoder loss 0.624\n",
            "\n",
            "Epoch 136\n",
            "Critic training done in epoch 136\n",
            "Encoder decoder training done in epoch 136\n",
            "critic x loss -1.489 critic z loss -0.246 \n",
            "encoder loss 1.866 decoder loss 0.637\n",
            "\n",
            "Epoch 137\n",
            "Critic training done in epoch 137\n",
            "Encoder decoder training done in epoch 137\n",
            "critic x loss -1.502 critic z loss -0.245 \n",
            "encoder loss 1.879 decoder loss 0.627\n",
            "\n",
            "Epoch 138\n",
            "Critic training done in epoch 138\n",
            "Encoder decoder training done in epoch 138\n",
            "critic x loss -1.514 critic z loss -0.249 \n",
            "encoder loss 1.892 decoder loss 0.632\n",
            "\n",
            "Epoch 139\n",
            "Critic training done in epoch 139\n",
            "Encoder decoder training done in epoch 139\n",
            "critic x loss -1.527 critic z loss -0.248 \n",
            "encoder loss 1.905 decoder loss 0.624\n",
            "\n",
            "Epoch 140\n",
            "Critic training done in epoch 140\n",
            "Encoder decoder training done in epoch 140\n",
            "critic x loss -1.540 critic z loss -0.250 \n",
            "encoder loss 1.918 decoder loss 0.634\n",
            "\n",
            "Epoch 141\n",
            "Critic training done in epoch 141\n",
            "Encoder decoder training done in epoch 141\n",
            "critic x loss -1.552 critic z loss -0.251 \n",
            "encoder loss 1.931 decoder loss 0.634\n",
            "\n",
            "Epoch 142\n",
            "Critic training done in epoch 142\n",
            "Encoder decoder training done in epoch 142\n",
            "critic x loss -1.565 critic z loss -0.255 \n",
            "encoder loss 1.944 decoder loss 0.639\n",
            "\n",
            "Epoch 143\n",
            "Critic training done in epoch 143\n",
            "Encoder decoder training done in epoch 143\n",
            "critic x loss -1.578 critic z loss -0.256 \n",
            "encoder loss 1.957 decoder loss 0.631\n",
            "\n",
            "Epoch 144\n",
            "Critic training done in epoch 144\n",
            "Encoder decoder training done in epoch 144\n",
            "critic x loss -1.590 critic z loss -0.256 \n",
            "encoder loss 1.970 decoder loss 0.646\n",
            "\n",
            "Epoch 145\n",
            "Critic training done in epoch 145\n",
            "Encoder decoder training done in epoch 145\n",
            "critic x loss -1.603 critic z loss -0.262 \n",
            "encoder loss 1.983 decoder loss 0.641\n",
            "\n",
            "Epoch 146\n",
            "Critic training done in epoch 146\n",
            "Encoder decoder training done in epoch 146\n",
            "critic x loss -1.616 critic z loss -0.262 \n",
            "encoder loss 1.996 decoder loss 0.642\n",
            "\n",
            "Epoch 147\n",
            "Critic training done in epoch 147\n",
            "Encoder decoder training done in epoch 147\n",
            "critic x loss -1.628 critic z loss -0.262 \n",
            "encoder loss 2.009 decoder loss 0.639\n",
            "\n",
            "Epoch 148\n",
            "Critic training done in epoch 148\n",
            "Encoder decoder training done in epoch 148\n",
            "critic x loss -1.641 critic z loss -0.263 \n",
            "encoder loss 2.022 decoder loss 0.649\n",
            "\n",
            "Epoch 149\n",
            "Critic training done in epoch 149\n",
            "Encoder decoder training done in epoch 149\n",
            "critic x loss -1.654 critic z loss -0.265 \n",
            "encoder loss 2.035 decoder loss 0.643\n",
            "\n",
            "Epoch 150\n",
            "Critic training done in epoch 150\n",
            "Encoder decoder training done in epoch 150\n",
            "critic x loss -1.666 critic z loss -0.269 \n",
            "encoder loss 2.048 decoder loss 0.646\n",
            "\n",
            "Epoch 151\n",
            "Critic training done in epoch 151\n",
            "Encoder decoder training done in epoch 151\n",
            "critic x loss -1.679 critic z loss -0.272 \n",
            "encoder loss 2.061 decoder loss 0.645\n",
            "\n",
            "Epoch 152\n",
            "Critic training done in epoch 152\n",
            "Encoder decoder training done in epoch 152\n",
            "critic x loss -1.692 critic z loss -0.270 \n",
            "encoder loss 2.074 decoder loss 0.656\n",
            "\n",
            "Epoch 153\n",
            "Critic training done in epoch 153\n",
            "Encoder decoder training done in epoch 153\n",
            "critic x loss -1.705 critic z loss -0.273 \n",
            "encoder loss 2.087 decoder loss 0.650\n",
            "\n",
            "Epoch 154\n",
            "Critic training done in epoch 154\n",
            "Encoder decoder training done in epoch 154\n",
            "critic x loss -1.717 critic z loss -0.274 \n",
            "encoder loss 2.100 decoder loss 0.654\n",
            "\n",
            "Epoch 155\n",
            "Critic training done in epoch 155\n",
            "Encoder decoder training done in epoch 155\n",
            "critic x loss -1.730 critic z loss -0.275 \n",
            "encoder loss 2.113 decoder loss 0.654\n",
            "\n",
            "Epoch 156\n",
            "Critic training done in epoch 156\n",
            "Encoder decoder training done in epoch 156\n",
            "critic x loss -1.742 critic z loss -0.274 \n",
            "encoder loss 2.126 decoder loss 0.659\n",
            "\n",
            "Epoch 157\n",
            "Critic training done in epoch 157\n",
            "Encoder decoder training done in epoch 157\n",
            "critic x loss -1.755 critic z loss -0.278 \n",
            "encoder loss 2.139 decoder loss 0.659\n",
            "\n",
            "Epoch 158\n",
            "Critic training done in epoch 158\n",
            "Encoder decoder training done in epoch 158\n",
            "critic x loss -1.768 critic z loss -0.279 \n",
            "encoder loss 2.152 decoder loss 0.653\n",
            "\n",
            "Epoch 159\n",
            "Critic training done in epoch 159\n",
            "Encoder decoder training done in epoch 159\n",
            "critic x loss -1.780 critic z loss -0.284 \n",
            "encoder loss 2.165 decoder loss 0.653\n",
            "\n",
            "Epoch 160\n",
            "Critic training done in epoch 160\n",
            "Encoder decoder training done in epoch 160\n",
            "critic x loss -1.793 critic z loss -0.281 \n",
            "encoder loss 2.178 decoder loss 0.663\n",
            "\n",
            "Epoch 161\n",
            "Critic training done in epoch 161\n",
            "Encoder decoder training done in epoch 161\n",
            "critic x loss -1.806 critic z loss -0.284 \n",
            "encoder loss 2.191 decoder loss 0.670\n",
            "\n",
            "Epoch 162\n",
            "Critic training done in epoch 162\n",
            "Encoder decoder training done in epoch 162\n",
            "critic x loss -1.819 critic z loss -0.288 \n",
            "encoder loss 2.204 decoder loss 0.664\n",
            "\n",
            "Epoch 163\n",
            "Critic training done in epoch 163\n",
            "Encoder decoder training done in epoch 163\n",
            "critic x loss -1.831 critic z loss -0.290 \n",
            "encoder loss 2.217 decoder loss 0.670\n",
            "\n",
            "Epoch 164\n",
            "Critic training done in epoch 164\n",
            "Encoder decoder training done in epoch 164\n",
            "critic x loss -1.844 critic z loss -0.287 \n",
            "encoder loss 2.230 decoder loss 0.671\n",
            "\n",
            "Epoch 165\n",
            "Critic training done in epoch 165\n",
            "Encoder decoder training done in epoch 165\n",
            "critic x loss -1.857 critic z loss -0.290 \n",
            "encoder loss 2.243 decoder loss 0.667\n",
            "\n",
            "Epoch 166\n",
            "Critic training done in epoch 166\n",
            "Encoder decoder training done in epoch 166\n",
            "critic x loss -1.869 critic z loss -0.293 \n",
            "encoder loss 2.256 decoder loss 0.667\n",
            "\n",
            "Epoch 167\n",
            "Critic training done in epoch 167\n",
            "Encoder decoder training done in epoch 167\n",
            "critic x loss -1.882 critic z loss -0.295 \n",
            "encoder loss 2.269 decoder loss 0.670\n",
            "\n",
            "Epoch 168\n",
            "Critic training done in epoch 168\n",
            "Encoder decoder training done in epoch 168\n",
            "critic x loss -1.895 critic z loss -0.295 \n",
            "encoder loss 2.282 decoder loss 0.681\n",
            "\n",
            "Epoch 169\n",
            "Critic training done in epoch 169\n",
            "Encoder decoder training done in epoch 169\n",
            "critic x loss -1.907 critic z loss -0.299 \n",
            "encoder loss 2.295 decoder loss 0.682\n",
            "\n",
            "Epoch 170\n",
            "Critic training done in epoch 170\n",
            "Encoder decoder training done in epoch 170\n",
            "critic x loss -1.920 critic z loss -0.300 \n",
            "encoder loss 2.308 decoder loss 0.677\n",
            "\n",
            "Epoch 171\n",
            "Critic training done in epoch 171\n",
            "Encoder decoder training done in epoch 171\n",
            "critic x loss -1.933 critic z loss -0.299 \n",
            "encoder loss 2.321 decoder loss 0.690\n",
            "\n",
            "Epoch 172\n",
            "Critic training done in epoch 172\n",
            "Encoder decoder training done in epoch 172\n",
            "critic x loss -1.945 critic z loss -0.301 \n",
            "encoder loss 2.334 decoder loss 0.679\n",
            "\n",
            "Epoch 173\n",
            "Critic training done in epoch 173\n",
            "Encoder decoder training done in epoch 173\n",
            "critic x loss -1.958 critic z loss -0.305 \n",
            "encoder loss 2.347 decoder loss 0.687\n",
            "\n",
            "Epoch 174\n",
            "Critic training done in epoch 174\n",
            "Encoder decoder training done in epoch 174\n",
            "critic x loss -1.971 critic z loss -0.304 \n",
            "encoder loss 2.360 decoder loss 0.678\n",
            "\n",
            "Epoch 175\n",
            "Critic training done in epoch 175\n",
            "Encoder decoder training done in epoch 175\n",
            "critic x loss -1.983 critic z loss -0.309 \n",
            "encoder loss 2.373 decoder loss 0.684\n",
            "\n",
            "Epoch 176\n",
            "Critic training done in epoch 176\n",
            "Encoder decoder training done in epoch 176\n",
            "critic x loss -1.996 critic z loss -0.309 \n",
            "encoder loss 2.386 decoder loss 0.685\n",
            "\n",
            "Epoch 177\n",
            "Critic training done in epoch 177\n",
            "Encoder decoder training done in epoch 177\n",
            "critic x loss -2.008 critic z loss -0.310 \n",
            "encoder loss 2.399 decoder loss 0.691\n",
            "\n",
            "Epoch 178\n",
            "Critic training done in epoch 178\n",
            "Encoder decoder training done in epoch 178\n",
            "critic x loss -2.021 critic z loss -0.314 \n",
            "encoder loss 2.412 decoder loss 0.691\n",
            "\n",
            "Epoch 179\n",
            "Critic training done in epoch 179\n",
            "Encoder decoder training done in epoch 179\n",
            "critic x loss -2.034 critic z loss -0.310 \n",
            "encoder loss 2.425 decoder loss 0.692\n",
            "\n",
            "Epoch 180\n",
            "Critic training done in epoch 180\n",
            "Encoder decoder training done in epoch 180\n",
            "critic x loss -2.046 critic z loss -0.318 \n",
            "encoder loss 2.438 decoder loss 0.699\n",
            "\n",
            "Epoch 181\n",
            "Critic training done in epoch 181\n",
            "Encoder decoder training done in epoch 181\n",
            "critic x loss -2.059 critic z loss -0.318 \n",
            "encoder loss 2.451 decoder loss 0.696\n",
            "\n",
            "Epoch 182\n",
            "Critic training done in epoch 182\n",
            "Encoder decoder training done in epoch 182\n",
            "critic x loss -2.072 critic z loss -0.320 \n",
            "encoder loss 2.464 decoder loss 0.694\n",
            "\n",
            "Epoch 183\n",
            "Critic training done in epoch 183\n",
            "Encoder decoder training done in epoch 183\n",
            "critic x loss -2.084 critic z loss -0.321 \n",
            "encoder loss 2.477 decoder loss 0.700\n",
            "\n",
            "Epoch 184\n",
            "Critic training done in epoch 184\n",
            "Encoder decoder training done in epoch 184\n",
            "critic x loss -2.097 critic z loss -0.321 \n",
            "encoder loss 2.490 decoder loss 0.698\n",
            "\n",
            "Epoch 185\n",
            "Critic training done in epoch 185\n",
            "Encoder decoder training done in epoch 185\n",
            "critic x loss -2.109 critic z loss -0.327 \n",
            "encoder loss 2.503 decoder loss 0.701\n",
            "\n",
            "Epoch 186\n",
            "Critic training done in epoch 186\n",
            "Encoder decoder training done in epoch 186\n",
            "critic x loss -2.122 critic z loss -0.326 \n",
            "encoder loss 2.516 decoder loss 0.705\n",
            "\n",
            "Epoch 187\n",
            "Critic training done in epoch 187\n",
            "Encoder decoder training done in epoch 187\n",
            "critic x loss -2.135 critic z loss -0.325 \n",
            "encoder loss 2.529 decoder loss 0.706\n",
            "\n",
            "Epoch 188\n",
            "Critic training done in epoch 188\n",
            "Encoder decoder training done in epoch 188\n",
            "critic x loss -2.147 critic z loss -0.328 \n",
            "encoder loss 2.542 decoder loss 0.711\n",
            "\n",
            "Epoch 189\n",
            "Critic training done in epoch 189\n",
            "Encoder decoder training done in epoch 189\n",
            "critic x loss -2.160 critic z loss -0.329 \n",
            "encoder loss 2.555 decoder loss 0.709\n",
            "\n",
            "Epoch 190\n",
            "Critic training done in epoch 190\n",
            "Encoder decoder training done in epoch 190\n",
            "critic x loss -2.172 critic z loss -0.333 \n",
            "encoder loss 2.568 decoder loss 0.706\n",
            "\n",
            "Epoch 191\n",
            "Critic training done in epoch 191\n",
            "Encoder decoder training done in epoch 191\n",
            "critic x loss -2.185 critic z loss -0.333 \n",
            "encoder loss 2.581 decoder loss 0.709\n",
            "\n",
            "Epoch 192\n",
            "Critic training done in epoch 192\n",
            "Encoder decoder training done in epoch 192\n",
            "critic x loss -2.198 critic z loss -0.336 \n",
            "encoder loss 2.594 decoder loss 0.706\n",
            "\n",
            "Epoch 193\n",
            "Critic training done in epoch 193\n",
            "Encoder decoder training done in epoch 193\n",
            "critic x loss -2.210 critic z loss -0.338 \n",
            "encoder loss 2.607 decoder loss 0.712\n",
            "\n",
            "Epoch 194\n",
            "Critic training done in epoch 194\n",
            "Encoder decoder training done in epoch 194\n",
            "critic x loss -2.223 critic z loss -0.338 \n",
            "encoder loss 2.620 decoder loss 0.721\n",
            "\n",
            "Epoch 195\n",
            "Critic training done in epoch 195\n",
            "Encoder decoder training done in epoch 195\n",
            "critic x loss -2.235 critic z loss -0.341 \n",
            "encoder loss 2.633 decoder loss 0.711\n",
            "\n",
            "Epoch 196\n",
            "Critic training done in epoch 196\n",
            "Encoder decoder training done in epoch 196\n",
            "critic x loss -2.248 critic z loss -0.338 \n",
            "encoder loss 2.645 decoder loss 0.719\n",
            "\n",
            "Epoch 197\n",
            "Critic training done in epoch 197\n",
            "Encoder decoder training done in epoch 197\n",
            "critic x loss -2.260 critic z loss -0.343 \n",
            "encoder loss 2.658 decoder loss 0.720\n",
            "\n",
            "Epoch 198\n",
            "Critic training done in epoch 198\n",
            "Encoder decoder training done in epoch 198\n",
            "critic x loss -2.273 critic z loss -0.343 \n",
            "encoder loss 2.671 decoder loss 0.720\n",
            "\n",
            "Epoch 199\n",
            "Critic training done in epoch 199\n",
            "Encoder decoder training done in epoch 199\n",
            "critic x loss -2.285 critic z loss -0.345 \n",
            "encoder loss 2.684 decoder loss 0.728\n",
            "\n",
            "Epoch 200\n",
            "Critic training done in epoch 200\n",
            "Encoder decoder training done in epoch 200\n",
            "critic x loss -2.298 critic z loss -0.346 \n",
            "encoder loss 2.697 decoder loss 0.721\n",
            "\n",
            "Epoch 201\n",
            "Critic training done in epoch 201\n",
            "Encoder decoder training done in epoch 201\n",
            "critic x loss -2.310 critic z loss -0.347 \n",
            "encoder loss 2.710 decoder loss 0.725\n",
            "\n",
            "Epoch 202\n",
            "Critic training done in epoch 202\n",
            "Encoder decoder training done in epoch 202\n",
            "critic x loss -2.323 critic z loss -0.350 \n",
            "encoder loss 2.723 decoder loss 0.729\n",
            "\n",
            "Epoch 203\n",
            "Critic training done in epoch 203\n",
            "Encoder decoder training done in epoch 203\n",
            "critic x loss -2.335 critic z loss -0.353 \n",
            "encoder loss 2.736 decoder loss 0.732\n",
            "\n",
            "Epoch 204\n",
            "Critic training done in epoch 204\n",
            "Encoder decoder training done in epoch 204\n",
            "critic x loss -2.348 critic z loss -0.357 \n",
            "encoder loss 2.748 decoder loss 0.730\n",
            "\n",
            "Epoch 205\n",
            "Critic training done in epoch 205\n",
            "Encoder decoder training done in epoch 205\n",
            "critic x loss -2.360 critic z loss -0.357 \n",
            "encoder loss 2.761 decoder loss 0.736\n",
            "\n",
            "Epoch 206\n",
            "Critic training done in epoch 206\n",
            "Encoder decoder training done in epoch 206\n",
            "critic x loss -2.373 critic z loss -0.361 \n",
            "encoder loss 2.774 decoder loss 0.731\n",
            "\n",
            "Epoch 207\n",
            "Critic training done in epoch 207\n",
            "Encoder decoder training done in epoch 207\n",
            "critic x loss -2.385 critic z loss -0.358 \n",
            "encoder loss 2.787 decoder loss 0.729\n",
            "\n",
            "Epoch 208\n",
            "Critic training done in epoch 208\n",
            "Encoder decoder training done in epoch 208\n",
            "critic x loss -2.397 critic z loss -0.359 \n",
            "encoder loss 2.799 decoder loss 0.739\n",
            "\n",
            "Epoch 209\n",
            "Critic training done in epoch 209\n",
            "Encoder decoder training done in epoch 209\n",
            "critic x loss -2.410 critic z loss -0.362 \n",
            "encoder loss 2.812 decoder loss 0.739\n",
            "\n",
            "Epoch 210\n",
            "Critic training done in epoch 210\n",
            "Encoder decoder training done in epoch 210\n",
            "critic x loss -2.422 critic z loss -0.363 \n",
            "encoder loss 2.825 decoder loss 0.736\n",
            "\n",
            "Epoch 211\n",
            "Critic training done in epoch 211\n",
            "Encoder decoder training done in epoch 211\n",
            "critic x loss -2.435 critic z loss -0.366 \n",
            "encoder loss 2.838 decoder loss 0.741\n",
            "\n",
            "Epoch 212\n",
            "Critic training done in epoch 212\n",
            "Encoder decoder training done in epoch 212\n",
            "critic x loss -2.447 critic z loss -0.365 \n",
            "encoder loss 2.851 decoder loss 0.741\n",
            "\n",
            "Epoch 213\n",
            "Critic training done in epoch 213\n",
            "Encoder decoder training done in epoch 213\n",
            "critic x loss -2.459 critic z loss -0.369 \n",
            "encoder loss 2.864 decoder loss 0.745\n",
            "\n",
            "Epoch 214\n",
            "Critic training done in epoch 214\n",
            "Encoder decoder training done in epoch 214\n",
            "critic x loss -2.472 critic z loss -0.369 \n",
            "encoder loss 2.876 decoder loss 0.747\n",
            "\n",
            "Epoch 215\n",
            "Critic training done in epoch 215\n",
            "Encoder decoder training done in epoch 215\n",
            "critic x loss -2.484 critic z loss -0.371 \n",
            "encoder loss 2.889 decoder loss 0.753\n",
            "\n",
            "Epoch 216\n",
            "Critic training done in epoch 216\n",
            "Encoder decoder training done in epoch 216\n",
            "critic x loss -2.496 critic z loss -0.375 \n",
            "encoder loss 2.902 decoder loss 0.748\n",
            "\n",
            "Epoch 217\n",
            "Critic training done in epoch 217\n",
            "Encoder decoder training done in epoch 217\n",
            "critic x loss -2.509 critic z loss -0.373 \n",
            "encoder loss 2.914 decoder loss 0.746\n",
            "\n",
            "Epoch 218\n",
            "Critic training done in epoch 218\n",
            "Encoder decoder training done in epoch 218\n",
            "critic x loss -2.521 critic z loss -0.376 \n",
            "encoder loss 2.928 decoder loss 0.757\n",
            "\n",
            "Epoch 219\n",
            "Critic training done in epoch 219\n",
            "Encoder decoder training done in epoch 219\n",
            "critic x loss -2.534 critic z loss -0.381 \n",
            "encoder loss 2.940 decoder loss 0.749\n",
            "\n",
            "Epoch 220\n",
            "Critic training done in epoch 220\n",
            "Encoder decoder training done in epoch 220\n",
            "critic x loss -2.546 critic z loss -0.379 \n",
            "encoder loss 2.953 decoder loss 0.755\n",
            "\n",
            "Epoch 221\n",
            "Critic training done in epoch 221\n",
            "Encoder decoder training done in epoch 221\n",
            "critic x loss -2.558 critic z loss -0.380 \n",
            "encoder loss 2.965 decoder loss 0.754\n",
            "\n",
            "Epoch 222\n",
            "Critic training done in epoch 222\n",
            "Encoder decoder training done in epoch 222\n",
            "critic x loss -2.570 critic z loss -0.385 \n",
            "encoder loss 2.978 decoder loss 0.757\n",
            "\n",
            "Epoch 223\n",
            "Critic training done in epoch 223\n",
            "Encoder decoder training done in epoch 223\n",
            "critic x loss -2.583 critic z loss -0.382 \n",
            "encoder loss 2.990 decoder loss 0.760\n",
            "\n",
            "Epoch 224\n",
            "Critic training done in epoch 224\n",
            "Encoder decoder training done in epoch 224\n",
            "critic x loss -2.595 critic z loss -0.383 \n",
            "encoder loss 3.003 decoder loss 0.759\n",
            "\n",
            "Epoch 225\n",
            "Critic training done in epoch 225\n",
            "Encoder decoder training done in epoch 225\n",
            "critic x loss -2.607 critic z loss -0.388 \n",
            "encoder loss 3.016 decoder loss 0.763\n",
            "\n",
            "Epoch 226\n",
            "Critic training done in epoch 226\n",
            "Encoder decoder training done in epoch 226\n",
            "critic x loss -2.619 critic z loss -0.390 \n",
            "encoder loss 3.028 decoder loss 0.759\n",
            "\n",
            "Epoch 227\n",
            "Critic training done in epoch 227\n",
            "Encoder decoder training done in epoch 227\n",
            "critic x loss -2.632 critic z loss -0.390 \n",
            "encoder loss 3.040 decoder loss 0.763\n",
            "\n",
            "Epoch 228\n",
            "Critic training done in epoch 228\n",
            "Encoder decoder training done in epoch 228\n",
            "critic x loss -2.644 critic z loss -0.388 \n",
            "encoder loss 3.053 decoder loss 0.763\n",
            "\n",
            "Epoch 229\n",
            "Critic training done in epoch 229\n",
            "Encoder decoder training done in epoch 229\n",
            "critic x loss -2.656 critic z loss -0.393 \n",
            "encoder loss 3.066 decoder loss 0.767\n",
            "\n",
            "Epoch 230\n",
            "Critic training done in epoch 230\n",
            "Encoder decoder training done in epoch 230\n",
            "critic x loss -2.668 critic z loss -0.397 \n",
            "encoder loss 3.078 decoder loss 0.765\n",
            "\n",
            "Epoch 231\n",
            "Critic training done in epoch 231\n",
            "Encoder decoder training done in epoch 231\n",
            "critic x loss -2.680 critic z loss -0.397 \n",
            "encoder loss 3.091 decoder loss 0.764\n",
            "\n",
            "Epoch 232\n",
            "Critic training done in epoch 232\n",
            "Encoder decoder training done in epoch 232\n",
            "critic x loss -2.692 critic z loss -0.398 \n",
            "encoder loss 3.104 decoder loss 0.762\n",
            "\n",
            "Epoch 233\n",
            "Critic training done in epoch 233\n",
            "Encoder decoder training done in epoch 233\n",
            "critic x loss -2.704 critic z loss -0.400 \n",
            "encoder loss 3.115 decoder loss 0.769\n",
            "\n",
            "Epoch 234\n",
            "Critic training done in epoch 234\n",
            "Encoder decoder training done in epoch 234\n",
            "critic x loss -2.716 critic z loss -0.404 \n",
            "encoder loss 3.128 decoder loss 0.775\n",
            "\n",
            "Epoch 235\n",
            "Critic training done in epoch 235\n",
            "Encoder decoder training done in epoch 235\n",
            "critic x loss -2.728 critic z loss -0.402 \n",
            "encoder loss 3.141 decoder loss 0.775\n",
            "\n",
            "Epoch 236\n",
            "Critic training done in epoch 236\n",
            "Encoder decoder training done in epoch 236\n",
            "critic x loss -2.741 critic z loss -0.407 \n",
            "encoder loss 3.154 decoder loss 0.770\n",
            "\n",
            "Epoch 237\n",
            "Critic training done in epoch 237\n",
            "Encoder decoder training done in epoch 237\n",
            "critic x loss -2.753 critic z loss -0.406 \n",
            "encoder loss 3.166 decoder loss 0.774\n",
            "\n",
            "Epoch 238\n",
            "Critic training done in epoch 238\n",
            "Encoder decoder training done in epoch 238\n",
            "critic x loss -2.765 critic z loss -0.406 \n",
            "encoder loss 3.178 decoder loss 0.783\n",
            "\n",
            "Epoch 239\n",
            "Critic training done in epoch 239\n",
            "Encoder decoder training done in epoch 239\n",
            "critic x loss -2.777 critic z loss -0.411 \n",
            "encoder loss 3.191 decoder loss 0.777\n",
            "\n",
            "Epoch 240\n",
            "Critic training done in epoch 240\n",
            "Encoder decoder training done in epoch 240\n",
            "critic x loss -2.788 critic z loss -0.414 \n",
            "encoder loss 3.203 decoder loss 0.788\n",
            "\n",
            "Epoch 241\n",
            "Critic training done in epoch 241\n",
            "Encoder decoder training done in epoch 241\n",
            "critic x loss -2.800 critic z loss -0.413 \n",
            "encoder loss 3.215 decoder loss 0.785\n",
            "\n",
            "Epoch 242\n",
            "Critic training done in epoch 242\n",
            "Encoder decoder training done in epoch 242\n",
            "critic x loss -2.813 critic z loss -0.414 \n",
            "encoder loss 3.228 decoder loss 0.782\n",
            "\n",
            "Epoch 243\n",
            "Critic training done in epoch 243\n",
            "Encoder decoder training done in epoch 243\n",
            "critic x loss -2.824 critic z loss -0.414 \n",
            "encoder loss 3.240 decoder loss 0.791\n",
            "\n",
            "Epoch 244\n",
            "Critic training done in epoch 244\n",
            "Encoder decoder training done in epoch 244\n",
            "critic x loss -2.836 critic z loss -0.415 \n",
            "encoder loss 3.252 decoder loss 0.785\n",
            "\n",
            "Epoch 245\n",
            "Critic training done in epoch 245\n",
            "Encoder decoder training done in epoch 245\n",
            "critic x loss -2.848 critic z loss -0.418 \n",
            "encoder loss 3.264 decoder loss 0.791\n",
            "\n",
            "Epoch 246\n",
            "Critic training done in epoch 246\n",
            "Encoder decoder training done in epoch 246\n",
            "critic x loss -2.860 critic z loss -0.420 \n",
            "encoder loss 3.277 decoder loss 0.793\n",
            "\n",
            "Epoch 247\n",
            "Critic training done in epoch 247\n",
            "Encoder decoder training done in epoch 247\n",
            "critic x loss -2.872 critic z loss -0.424 \n",
            "encoder loss 3.289 decoder loss 0.793\n",
            "\n",
            "Epoch 248\n",
            "Critic training done in epoch 248\n",
            "Encoder decoder training done in epoch 248\n",
            "critic x loss -2.884 critic z loss -0.422 \n",
            "encoder loss 3.301 decoder loss 0.794\n",
            "\n",
            "Epoch 249\n",
            "Critic training done in epoch 249\n",
            "Encoder decoder training done in epoch 249\n",
            "critic x loss -2.896 critic z loss -0.425 \n",
            "encoder loss 3.314 decoder loss 0.793\n",
            "\n",
            "Epoch 250\n",
            "Critic training done in epoch 250\n",
            "Encoder decoder training done in epoch 250\n",
            "critic x loss -2.907 critic z loss -0.426 \n",
            "encoder loss 3.326 decoder loss 0.791\n",
            "\n",
            "Epoch 251\n",
            "Critic training done in epoch 251\n",
            "Encoder decoder training done in epoch 251\n",
            "critic x loss -2.919 critic z loss -0.428 \n",
            "encoder loss 3.338 decoder loss 0.797\n",
            "\n",
            "Epoch 252\n",
            "Critic training done in epoch 252\n",
            "Encoder decoder training done in epoch 252\n",
            "critic x loss -2.931 critic z loss -0.432 \n",
            "encoder loss 3.350 decoder loss 0.800\n",
            "\n",
            "Epoch 253\n",
            "Critic training done in epoch 253\n",
            "Encoder decoder training done in epoch 253\n",
            "critic x loss -2.943 critic z loss -0.432 \n",
            "encoder loss 3.361 decoder loss 0.798\n",
            "\n",
            "Epoch 254\n",
            "Critic training done in epoch 254\n",
            "Encoder decoder training done in epoch 254\n",
            "critic x loss -2.954 critic z loss -0.430 \n",
            "encoder loss 3.374 decoder loss 0.797\n",
            "\n",
            "Epoch 255\n",
            "Critic training done in epoch 255\n",
            "Encoder decoder training done in epoch 255\n",
            "critic x loss -2.966 critic z loss -0.435 \n",
            "encoder loss 3.386 decoder loss 0.801\n",
            "\n",
            "Epoch 256\n",
            "Critic training done in epoch 256\n",
            "Encoder decoder training done in epoch 256\n",
            "critic x loss -2.978 critic z loss -0.435 \n",
            "encoder loss 3.398 decoder loss 0.796\n",
            "\n",
            "Epoch 257\n",
            "Critic training done in epoch 257\n",
            "Encoder decoder training done in epoch 257\n",
            "critic x loss -2.989 critic z loss -0.438 \n",
            "encoder loss 3.411 decoder loss 0.809\n",
            "\n",
            "Epoch 258\n",
            "Critic training done in epoch 258\n",
            "Encoder decoder training done in epoch 258\n",
            "critic x loss -3.001 critic z loss -0.438 \n",
            "encoder loss 3.422 decoder loss 0.803\n",
            "\n",
            "Epoch 259\n",
            "Critic training done in epoch 259\n",
            "Encoder decoder training done in epoch 259\n",
            "critic x loss -3.012 critic z loss -0.438 \n",
            "encoder loss 3.434 decoder loss 0.805\n",
            "\n",
            "Epoch 260\n",
            "Critic training done in epoch 260\n",
            "Encoder decoder training done in epoch 260\n",
            "critic x loss -3.024 critic z loss -0.442 \n",
            "encoder loss 3.445 decoder loss 0.818\n",
            "\n",
            "Epoch 261\n",
            "Critic training done in epoch 261\n",
            "Encoder decoder training done in epoch 261\n",
            "critic x loss -3.036 critic z loss -0.441 \n",
            "encoder loss 3.458 decoder loss 0.811\n",
            "\n",
            "Epoch 262\n",
            "Critic training done in epoch 262\n",
            "Encoder decoder training done in epoch 262\n",
            "critic x loss -3.047 critic z loss -0.442 \n",
            "encoder loss 3.470 decoder loss 0.812\n",
            "\n",
            "Epoch 263\n",
            "Critic training done in epoch 263\n",
            "Encoder decoder training done in epoch 263\n",
            "critic x loss -3.059 critic z loss -0.445 \n",
            "encoder loss 3.482 decoder loss 0.815\n",
            "\n",
            "Epoch 264\n",
            "Critic training done in epoch 264\n",
            "Encoder decoder training done in epoch 264\n",
            "critic x loss -3.070 critic z loss -0.447 \n",
            "encoder loss 3.493 decoder loss 0.814\n",
            "\n",
            "Epoch 265\n",
            "Critic training done in epoch 265\n",
            "Encoder decoder training done in epoch 265\n",
            "critic x loss -3.081 critic z loss -0.449 \n",
            "encoder loss 3.505 decoder loss 0.808\n",
            "\n",
            "Epoch 266\n",
            "Critic training done in epoch 266\n",
            "Encoder decoder training done in epoch 266\n",
            "critic x loss -3.093 critic z loss -0.453 \n",
            "encoder loss 3.518 decoder loss 0.824\n",
            "\n",
            "Epoch 267\n",
            "Critic training done in epoch 267\n",
            "Encoder decoder training done in epoch 267\n",
            "critic x loss -3.105 critic z loss -0.450 \n",
            "encoder loss 3.529 decoder loss 0.821\n",
            "\n",
            "Epoch 268\n",
            "Critic training done in epoch 268\n",
            "Encoder decoder training done in epoch 268\n",
            "critic x loss -3.116 critic z loss -0.453 \n",
            "encoder loss 3.541 decoder loss 0.821\n",
            "\n",
            "Epoch 269\n",
            "Critic training done in epoch 269\n",
            "Encoder decoder training done in epoch 269\n",
            "critic x loss -3.127 critic z loss -0.451 \n",
            "encoder loss 3.553 decoder loss 0.822\n",
            "\n",
            "Epoch 270\n",
            "Critic training done in epoch 270\n",
            "Encoder decoder training done in epoch 270\n",
            "critic x loss -3.139 critic z loss -0.453 \n",
            "encoder loss 3.564 decoder loss 0.826\n",
            "\n",
            "Epoch 271\n",
            "Critic training done in epoch 271\n",
            "Encoder decoder training done in epoch 271\n",
            "critic x loss -3.150 critic z loss -0.457 \n",
            "encoder loss 3.576 decoder loss 0.822\n",
            "\n",
            "Epoch 272\n",
            "Critic training done in epoch 272\n",
            "Encoder decoder training done in epoch 272\n",
            "critic x loss -3.161 critic z loss -0.462 \n",
            "encoder loss 3.587 decoder loss 0.821\n",
            "\n",
            "Epoch 273\n",
            "Critic training done in epoch 273\n",
            "Encoder decoder training done in epoch 273\n",
            "critic x loss -3.172 critic z loss -0.461 \n",
            "encoder loss 3.599 decoder loss 0.827\n",
            "\n",
            "Epoch 274\n",
            "Critic training done in epoch 274\n",
            "Encoder decoder training done in epoch 274\n",
            "critic x loss -3.184 critic z loss -0.463 \n",
            "encoder loss 3.611 decoder loss 0.832\n",
            "\n",
            "Epoch 275\n",
            "Critic training done in epoch 275\n",
            "Encoder decoder training done in epoch 275\n",
            "critic x loss -3.195 critic z loss -0.462 \n",
            "encoder loss 3.622 decoder loss 0.838\n",
            "\n",
            "Epoch 276\n",
            "Critic training done in epoch 276\n",
            "Encoder decoder training done in epoch 276\n",
            "critic x loss -3.206 critic z loss -0.464 \n",
            "encoder loss 3.634 decoder loss 0.831\n",
            "\n",
            "Epoch 277\n",
            "Critic training done in epoch 277\n",
            "Encoder decoder training done in epoch 277\n",
            "critic x loss -3.217 critic z loss -0.467 \n",
            "encoder loss 3.646 decoder loss 0.828\n",
            "\n",
            "Epoch 278\n",
            "Critic training done in epoch 278\n",
            "Encoder decoder training done in epoch 278\n",
            "critic x loss -3.229 critic z loss -0.467 \n",
            "encoder loss 3.656 decoder loss 0.835\n",
            "\n",
            "Epoch 279\n",
            "Critic training done in epoch 279\n",
            "Encoder decoder training done in epoch 279\n",
            "critic x loss -3.239 critic z loss -0.472 \n",
            "encoder loss 3.668 decoder loss 0.837\n",
            "\n",
            "Epoch 280\n",
            "Critic training done in epoch 280\n",
            "Encoder decoder training done in epoch 280\n",
            "critic x loss -3.250 critic z loss -0.469 \n",
            "encoder loss 3.680 decoder loss 0.840\n",
            "\n",
            "Epoch 281\n",
            "Critic training done in epoch 281\n",
            "Encoder decoder training done in epoch 281\n",
            "critic x loss -3.262 critic z loss -0.472 \n",
            "encoder loss 3.691 decoder loss 0.839\n",
            "\n",
            "Epoch 282\n",
            "Critic training done in epoch 282\n",
            "Encoder decoder training done in epoch 282\n",
            "critic x loss -3.273 critic z loss -0.474 \n",
            "encoder loss 3.703 decoder loss 0.840\n",
            "\n",
            "Epoch 283\n",
            "Critic training done in epoch 283\n",
            "Encoder decoder training done in epoch 283\n",
            "critic x loss -3.284 critic z loss -0.475 \n",
            "encoder loss 3.713 decoder loss 0.841\n",
            "\n",
            "Epoch 284\n",
            "Critic training done in epoch 284\n",
            "Encoder decoder training done in epoch 284\n",
            "critic x loss -3.295 critic z loss -0.479 \n",
            "encoder loss 3.725 decoder loss 0.848\n",
            "\n",
            "Epoch 285\n",
            "Critic training done in epoch 285\n",
            "Encoder decoder training done in epoch 285\n",
            "critic x loss -3.305 critic z loss -0.479 \n",
            "encoder loss 3.736 decoder loss 0.845\n",
            "\n",
            "Epoch 286\n",
            "Critic training done in epoch 286\n",
            "Encoder decoder training done in epoch 286\n",
            "critic x loss -3.316 critic z loss -0.479 \n",
            "encoder loss 3.748 decoder loss 0.852\n",
            "\n",
            "Epoch 287\n",
            "Critic training done in epoch 287\n",
            "Encoder decoder training done in epoch 287\n",
            "critic x loss -3.327 critic z loss -0.481 \n",
            "encoder loss 3.759 decoder loss 0.844\n",
            "\n",
            "Epoch 288\n",
            "Critic training done in epoch 288\n",
            "Encoder decoder training done in epoch 288\n",
            "critic x loss -3.339 critic z loss -0.480 \n",
            "encoder loss 3.770 decoder loss 0.860\n",
            "\n",
            "Epoch 289\n",
            "Critic training done in epoch 289\n",
            "Encoder decoder training done in epoch 289\n",
            "critic x loss -3.349 critic z loss -0.482 \n",
            "encoder loss 3.781 decoder loss 0.853\n",
            "\n",
            "Epoch 290\n",
            "Critic training done in epoch 290\n",
            "Encoder decoder training done in epoch 290\n",
            "critic x loss -3.360 critic z loss -0.483 \n",
            "encoder loss 3.792 decoder loss 0.859\n",
            "\n",
            "Epoch 291\n",
            "Critic training done in epoch 291\n",
            "Encoder decoder training done in epoch 291\n",
            "critic x loss -3.370 critic z loss -0.484 \n",
            "encoder loss 3.804 decoder loss 0.859\n",
            "\n",
            "Epoch 292\n",
            "Critic training done in epoch 292\n",
            "Encoder decoder training done in epoch 292\n",
            "critic x loss -3.381 critic z loss -0.489 \n",
            "encoder loss 3.814 decoder loss 0.850\n",
            "\n",
            "Epoch 293\n",
            "Critic training done in epoch 293\n",
            "Encoder decoder training done in epoch 293\n",
            "critic x loss -3.392 critic z loss -0.490 \n",
            "encoder loss 3.825 decoder loss 0.855\n",
            "\n",
            "Epoch 294\n",
            "Critic training done in epoch 294\n",
            "Encoder decoder training done in epoch 294\n",
            "critic x loss -3.402 critic z loss -0.493 \n",
            "encoder loss 3.837 decoder loss 0.859\n",
            "\n",
            "Epoch 295\n",
            "Critic training done in epoch 295\n",
            "Encoder decoder training done in epoch 295\n",
            "critic x loss -3.413 critic z loss -0.495 \n",
            "encoder loss 3.848 decoder loss 0.857\n",
            "\n",
            "Epoch 296\n",
            "Critic training done in epoch 296\n",
            "Encoder decoder training done in epoch 296\n",
            "critic x loss -3.424 critic z loss -0.496 \n",
            "encoder loss 3.858 decoder loss 0.862\n",
            "\n",
            "Epoch 297\n",
            "Critic training done in epoch 297\n",
            "Encoder decoder training done in epoch 297\n",
            "critic x loss -3.435 critic z loss -0.497 \n",
            "encoder loss 3.869 decoder loss 0.866\n",
            "\n",
            "Epoch 298\n",
            "Critic training done in epoch 298\n",
            "Encoder decoder training done in epoch 298\n",
            "critic x loss -3.445 critic z loss -0.501 \n",
            "encoder loss 3.880 decoder loss 0.862\n",
            "\n",
            "Epoch 299\n",
            "Critic training done in epoch 299\n",
            "Encoder decoder training done in epoch 299\n",
            "critic x loss -3.455 critic z loss -0.496 \n",
            "encoder loss 3.891 decoder loss 0.863\n",
            "\n",
            "Epoch 300\n",
            "Critic training done in epoch 300\n",
            "Encoder decoder training done in epoch 300\n",
            "critic x loss -3.466 critic z loss -0.502 \n",
            "encoder loss 3.902 decoder loss 0.866\n",
            "\n",
            "Epoch 301\n",
            "Critic training done in epoch 301\n",
            "Encoder decoder training done in epoch 301\n",
            "critic x loss -3.476 critic z loss -0.501 \n",
            "encoder loss 3.913 decoder loss 0.870\n",
            "\n",
            "Epoch 302\n",
            "Critic training done in epoch 302\n",
            "Encoder decoder training done in epoch 302\n",
            "critic x loss -3.486 critic z loss -0.503 \n",
            "encoder loss 3.923 decoder loss 0.871\n",
            "\n",
            "Epoch 303\n",
            "Critic training done in epoch 303\n",
            "Encoder decoder training done in epoch 303\n",
            "critic x loss -3.496 critic z loss -0.504 \n",
            "encoder loss 3.933 decoder loss 0.874\n",
            "\n",
            "Epoch 304\n",
            "Critic training done in epoch 304\n",
            "Encoder decoder training done in epoch 304\n",
            "critic x loss -3.507 critic z loss -0.507 \n",
            "encoder loss 3.945 decoder loss 0.874\n",
            "\n",
            "Epoch 305\n",
            "Critic training done in epoch 305\n",
            "Encoder decoder training done in epoch 305\n",
            "critic x loss -3.518 critic z loss -0.509 \n",
            "encoder loss 3.955 decoder loss 0.876\n",
            "\n",
            "Epoch 306\n",
            "Critic training done in epoch 306\n",
            "Encoder decoder training done in epoch 306\n",
            "critic x loss -3.528 critic z loss -0.510 \n",
            "encoder loss 3.966 decoder loss 0.880\n",
            "\n",
            "Epoch 307\n",
            "Critic training done in epoch 307\n",
            "Encoder decoder training done in epoch 307\n",
            "critic x loss -3.538 critic z loss -0.512 \n",
            "encoder loss 3.977 decoder loss 0.869\n",
            "\n",
            "Epoch 308\n",
            "Critic training done in epoch 308\n",
            "Encoder decoder training done in epoch 308\n",
            "critic x loss -3.548 critic z loss -0.510 \n",
            "encoder loss 3.988 decoder loss 0.868\n",
            "\n",
            "Epoch 309\n",
            "Critic training done in epoch 309\n",
            "Encoder decoder training done in epoch 309\n",
            "critic x loss -3.558 critic z loss -0.515 \n",
            "encoder loss 3.998 decoder loss 0.876\n",
            "\n",
            "Epoch 310\n",
            "Critic training done in epoch 310\n",
            "Encoder decoder training done in epoch 310\n",
            "critic x loss -3.568 critic z loss -0.516 \n",
            "encoder loss 4.008 decoder loss 0.880\n",
            "\n",
            "Epoch 311\n",
            "Critic training done in epoch 311\n",
            "Encoder decoder training done in epoch 311\n",
            "critic x loss -3.578 critic z loss -0.514 \n",
            "encoder loss 4.018 decoder loss 0.876\n",
            "\n",
            "Epoch 312\n",
            "Critic training done in epoch 312\n",
            "Encoder decoder training done in epoch 312\n",
            "critic x loss -3.589 critic z loss -0.518 \n",
            "encoder loss 4.028 decoder loss 0.877\n",
            "\n",
            "Epoch 313\n",
            "Critic training done in epoch 313\n",
            "Encoder decoder training done in epoch 313\n",
            "critic x loss -3.599 critic z loss -0.520 \n",
            "encoder loss 4.039 decoder loss 0.883\n",
            "\n",
            "Epoch 314\n",
            "Critic training done in epoch 314\n",
            "Encoder decoder training done in epoch 314\n",
            "critic x loss -3.608 critic z loss -0.521 \n",
            "encoder loss 4.049 decoder loss 0.883\n",
            "\n",
            "Epoch 315\n",
            "Critic training done in epoch 315\n",
            "Encoder decoder training done in epoch 315\n",
            "critic x loss -3.618 critic z loss -0.524 \n",
            "encoder loss 4.061 decoder loss 0.881\n",
            "\n",
            "Epoch 316\n",
            "Critic training done in epoch 316\n",
            "Encoder decoder training done in epoch 316\n",
            "critic x loss -3.628 critic z loss -0.524 \n",
            "encoder loss 4.071 decoder loss 0.882\n",
            "\n",
            "Epoch 317\n",
            "Critic training done in epoch 317\n",
            "Encoder decoder training done in epoch 317\n",
            "critic x loss -3.638 critic z loss -0.525 \n",
            "encoder loss 4.080 decoder loss 0.881\n",
            "\n",
            "Epoch 318\n",
            "Critic training done in epoch 318\n",
            "Encoder decoder training done in epoch 318\n",
            "critic x loss -3.648 critic z loss -0.524 \n",
            "encoder loss 4.089 decoder loss 0.882\n",
            "\n",
            "Epoch 319\n",
            "Critic training done in epoch 319\n",
            "Encoder decoder training done in epoch 319\n",
            "critic x loss -3.658 critic z loss -0.527 \n",
            "encoder loss 4.101 decoder loss 0.894\n",
            "\n",
            "Epoch 320\n",
            "Critic training done in epoch 320\n",
            "Encoder decoder training done in epoch 320\n",
            "critic x loss -3.667 critic z loss -0.530 \n",
            "encoder loss 4.111 decoder loss 0.893\n",
            "\n",
            "Epoch 321\n",
            "Critic training done in epoch 321\n",
            "Encoder decoder training done in epoch 321\n",
            "critic x loss -3.677 critic z loss -0.531 \n",
            "encoder loss 4.120 decoder loss 0.880\n",
            "\n",
            "Epoch 322\n",
            "Critic training done in epoch 322\n",
            "Encoder decoder training done in epoch 322\n",
            "critic x loss -3.687 critic z loss -0.533 \n",
            "encoder loss 4.129 decoder loss 0.895\n",
            "\n",
            "Epoch 323\n",
            "Critic training done in epoch 323\n",
            "Encoder decoder training done in epoch 323\n",
            "critic x loss -3.697 critic z loss -0.534 \n",
            "encoder loss 4.140 decoder loss 0.895\n",
            "\n",
            "Epoch 324\n",
            "Critic training done in epoch 324\n",
            "Encoder decoder training done in epoch 324\n",
            "critic x loss -3.706 critic z loss -0.537 \n",
            "encoder loss 4.151 decoder loss 0.899\n",
            "\n",
            "Epoch 325\n",
            "Critic training done in epoch 325\n",
            "Encoder decoder training done in epoch 325\n",
            "critic x loss -3.715 critic z loss -0.536 \n",
            "encoder loss 4.160 decoder loss 0.896\n",
            "\n",
            "Epoch 326\n",
            "Critic training done in epoch 326\n",
            "Encoder decoder training done in epoch 326\n",
            "critic x loss -3.725 critic z loss -0.540 \n",
            "encoder loss 4.170 decoder loss 0.898\n",
            "\n",
            "Epoch 327\n",
            "Critic training done in epoch 327\n",
            "Encoder decoder training done in epoch 327\n",
            "critic x loss -3.735 critic z loss -0.540 \n",
            "encoder loss 4.179 decoder loss 0.896\n",
            "\n",
            "Epoch 328\n",
            "Critic training done in epoch 328\n",
            "Encoder decoder training done in epoch 328\n",
            "critic x loss -3.743 critic z loss -0.540 \n",
            "encoder loss 4.190 decoder loss 0.898\n",
            "\n",
            "Epoch 329\n",
            "Critic training done in epoch 329\n",
            "Encoder decoder training done in epoch 329\n",
            "critic x loss -3.753 critic z loss -0.543 \n",
            "encoder loss 4.199 decoder loss 0.904\n",
            "\n",
            "Epoch 330\n",
            "Critic training done in epoch 330\n",
            "Encoder decoder training done in epoch 330\n",
            "critic x loss -3.762 critic z loss -0.546 \n",
            "encoder loss 4.209 decoder loss 0.903\n",
            "\n",
            "Epoch 331\n",
            "Critic training done in epoch 331\n",
            "Encoder decoder training done in epoch 331\n",
            "critic x loss -3.772 critic z loss -0.544 \n",
            "encoder loss 4.219 decoder loss 0.904\n",
            "\n",
            "Epoch 332\n",
            "Critic training done in epoch 332\n",
            "Encoder decoder training done in epoch 332\n",
            "critic x loss -3.780 critic z loss -0.545 \n",
            "encoder loss 4.228 decoder loss 0.908\n",
            "\n",
            "Epoch 333\n",
            "Critic training done in epoch 333\n",
            "Encoder decoder training done in epoch 333\n",
            "critic x loss -3.790 critic z loss -0.550 \n",
            "encoder loss 4.238 decoder loss 0.913\n",
            "\n",
            "Epoch 334\n",
            "Critic training done in epoch 334\n",
            "Encoder decoder training done in epoch 334\n",
            "critic x loss -3.799 critic z loss -0.550 \n",
            "encoder loss 4.247 decoder loss 0.908\n",
            "\n",
            "Epoch 335\n",
            "Critic training done in epoch 335\n",
            "Encoder decoder training done in epoch 335\n",
            "critic x loss -3.807 critic z loss -0.552 \n",
            "encoder loss 4.256 decoder loss 0.907\n",
            "\n",
            "Epoch 336\n",
            "Critic training done in epoch 336\n",
            "Encoder decoder training done in epoch 336\n",
            "critic x loss -3.818 critic z loss -0.554 \n",
            "encoder loss 4.264 decoder loss 0.902\n",
            "\n",
            "Epoch 337\n",
            "Critic training done in epoch 337\n",
            "Encoder decoder training done in epoch 337\n",
            "critic x loss -3.826 critic z loss -0.551 \n",
            "encoder loss 4.275 decoder loss 0.906\n",
            "\n",
            "Epoch 338\n",
            "Critic training done in epoch 338\n",
            "Encoder decoder training done in epoch 338\n",
            "critic x loss -3.835 critic z loss -0.560 \n",
            "encoder loss 4.285 decoder loss 0.920\n",
            "\n",
            "Epoch 339\n",
            "Critic training done in epoch 339\n",
            "Encoder decoder training done in epoch 339\n",
            "critic x loss -3.844 critic z loss -0.556 \n",
            "encoder loss 4.294 decoder loss 0.908\n",
            "\n",
            "Epoch 340\n",
            "Critic training done in epoch 340\n",
            "Encoder decoder training done in epoch 340\n",
            "critic x loss -3.853 critic z loss -0.559 \n",
            "encoder loss 4.302 decoder loss 0.910\n",
            "\n",
            "Epoch 341\n",
            "Critic training done in epoch 341\n",
            "Encoder decoder training done in epoch 341\n",
            "critic x loss -3.862 critic z loss -0.560 \n",
            "encoder loss 4.312 decoder loss 0.914\n",
            "\n",
            "Epoch 342\n",
            "Critic training done in epoch 342\n",
            "Encoder decoder training done in epoch 342\n",
            "critic x loss -3.870 critic z loss -0.560 \n",
            "encoder loss 4.321 decoder loss 0.910\n",
            "\n",
            "Epoch 343\n",
            "Critic training done in epoch 343\n",
            "Encoder decoder training done in epoch 343\n",
            "critic x loss -3.879 critic z loss -0.559 \n",
            "encoder loss 4.329 decoder loss 0.915\n",
            "\n",
            "Epoch 344\n",
            "Critic training done in epoch 344\n",
            "Encoder decoder training done in epoch 344\n",
            "critic x loss -3.888 critic z loss -0.562 \n",
            "encoder loss 4.339 decoder loss 0.923\n",
            "\n",
            "Epoch 345\n",
            "Critic training done in epoch 345\n",
            "Encoder decoder training done in epoch 345\n",
            "critic x loss -3.897 critic z loss -0.561 \n",
            "encoder loss 4.347 decoder loss 0.927\n",
            "\n",
            "Epoch 346\n",
            "Critic training done in epoch 346\n",
            "Encoder decoder training done in epoch 346\n",
            "critic x loss -3.905 critic z loss -0.566 \n",
            "encoder loss 4.356 decoder loss 0.916\n",
            "\n",
            "Epoch 347\n",
            "Critic training done in epoch 347\n",
            "Encoder decoder training done in epoch 347\n",
            "critic x loss -3.914 critic z loss -0.566 \n",
            "encoder loss 4.364 decoder loss 0.921\n",
            "\n",
            "Epoch 348\n",
            "Critic training done in epoch 348\n",
            "Encoder decoder training done in epoch 348\n",
            "critic x loss -3.922 critic z loss -0.570 \n",
            "encoder loss 4.374 decoder loss 0.919\n",
            "\n",
            "Epoch 349\n",
            "Critic training done in epoch 349\n",
            "Encoder decoder training done in epoch 349\n",
            "critic x loss -3.931 critic z loss -0.568 \n",
            "encoder loss 4.385 decoder loss 0.921\n",
            "\n",
            "Epoch 350\n",
            "Critic training done in epoch 350\n",
            "Encoder decoder training done in epoch 350\n",
            "critic x loss -3.939 critic z loss -0.569 \n",
            "encoder loss 4.393 decoder loss 0.923\n",
            "\n",
            "Epoch 351\n",
            "Critic training done in epoch 351\n",
            "Encoder decoder training done in epoch 351\n",
            "critic x loss -3.948 critic z loss -0.572 \n",
            "encoder loss 4.401 decoder loss 0.923\n",
            "\n",
            "Epoch 352\n",
            "Critic training done in epoch 352\n",
            "Encoder decoder training done in epoch 352\n",
            "critic x loss -3.957 critic z loss -0.575 \n",
            "encoder loss 4.409 decoder loss 0.925\n",
            "\n",
            "Epoch 353\n",
            "Critic training done in epoch 353\n",
            "Encoder decoder training done in epoch 353\n",
            "critic x loss -3.964 critic z loss -0.576 \n",
            "encoder loss 4.416 decoder loss 0.932\n",
            "\n",
            "Epoch 354\n",
            "Critic training done in epoch 354\n",
            "Encoder decoder training done in epoch 354\n",
            "critic x loss -3.973 critic z loss -0.574 \n",
            "encoder loss 4.425 decoder loss 0.929\n",
            "\n",
            "Epoch 355\n",
            "Critic training done in epoch 355\n",
            "Encoder decoder training done in epoch 355\n",
            "critic x loss -3.981 critic z loss -0.578 \n",
            "encoder loss 4.437 decoder loss 0.924\n",
            "\n",
            "Epoch 356\n",
            "Critic training done in epoch 356\n",
            "Encoder decoder training done in epoch 356\n",
            "critic x loss -3.989 critic z loss -0.581 \n",
            "encoder loss 4.442 decoder loss 0.937\n",
            "\n",
            "Epoch 357\n",
            "Critic training done in epoch 357\n",
            "Encoder decoder training done in epoch 357\n",
            "critic x loss -3.997 critic z loss -0.579 \n",
            "encoder loss 4.450 decoder loss 0.936\n",
            "\n",
            "Epoch 358\n",
            "Critic training done in epoch 358\n",
            "Encoder decoder training done in epoch 358\n",
            "critic x loss -4.005 critic z loss -0.581 \n",
            "encoder loss 4.459 decoder loss 0.934\n",
            "\n",
            "Epoch 359\n",
            "Critic training done in epoch 359\n",
            "Encoder decoder training done in epoch 359\n",
            "critic x loss -4.013 critic z loss -0.580 \n",
            "encoder loss 4.467 decoder loss 0.939\n",
            "\n",
            "Epoch 360\n",
            "Critic training done in epoch 360\n",
            "Encoder decoder training done in epoch 360\n",
            "critic x loss -4.021 critic z loss -0.582 \n",
            "encoder loss 4.477 decoder loss 0.947\n",
            "\n",
            "Epoch 361\n",
            "Critic training done in epoch 361\n",
            "Encoder decoder training done in epoch 361\n",
            "critic x loss -4.030 critic z loss -0.588 \n",
            "encoder loss 4.483 decoder loss 0.937\n",
            "\n",
            "Epoch 362\n",
            "Critic training done in epoch 362\n",
            "Encoder decoder training done in epoch 362\n",
            "critic x loss -4.037 critic z loss -0.585 \n",
            "encoder loss 4.492 decoder loss 0.941\n",
            "\n",
            "Epoch 363\n",
            "Critic training done in epoch 363\n",
            "Encoder decoder training done in epoch 363\n",
            "critic x loss -4.044 critic z loss -0.588 \n",
            "encoder loss 4.500 decoder loss 0.941\n",
            "\n",
            "Epoch 364\n",
            "Critic training done in epoch 364\n",
            "Encoder decoder training done in epoch 364\n",
            "critic x loss -4.052 critic z loss -0.593 \n",
            "encoder loss 4.510 decoder loss 0.952\n",
            "\n",
            "Epoch 365\n",
            "Critic training done in epoch 365\n",
            "Encoder decoder training done in epoch 365\n",
            "critic x loss -4.060 critic z loss -0.590 \n",
            "encoder loss 4.517 decoder loss 0.946\n",
            "\n",
            "Epoch 366\n",
            "Critic training done in epoch 366\n",
            "Encoder decoder training done in epoch 366\n",
            "critic x loss -4.068 critic z loss -0.591 \n",
            "encoder loss 4.524 decoder loss 0.947\n",
            "\n",
            "Epoch 367\n",
            "Critic training done in epoch 367\n",
            "Encoder decoder training done in epoch 367\n",
            "critic x loss -4.076 critic z loss -0.590 \n",
            "encoder loss 4.533 decoder loss 0.939\n",
            "\n",
            "Epoch 368\n",
            "Critic training done in epoch 368\n",
            "Encoder decoder training done in epoch 368\n",
            "critic x loss -4.084 critic z loss -0.595 \n",
            "encoder loss 4.542 decoder loss 0.948\n",
            "\n",
            "Epoch 369\n",
            "Critic training done in epoch 369\n",
            "Encoder decoder training done in epoch 369\n",
            "critic x loss -4.089 critic z loss -0.599 \n",
            "encoder loss 4.548 decoder loss 0.949\n",
            "\n",
            "Epoch 370\n",
            "Critic training done in epoch 370\n",
            "Encoder decoder training done in epoch 370\n",
            "critic x loss -4.098 critic z loss -0.598 \n",
            "encoder loss 4.555 decoder loss 0.954\n",
            "\n",
            "Epoch 371\n",
            "Critic training done in epoch 371\n",
            "Encoder decoder training done in epoch 371\n",
            "critic x loss -4.105 critic z loss -0.599 \n",
            "encoder loss 4.563 decoder loss 0.954\n",
            "\n",
            "Epoch 372\n",
            "Critic training done in epoch 372\n",
            "Encoder decoder training done in epoch 372\n",
            "critic x loss -4.112 critic z loss -0.601 \n",
            "encoder loss 4.570 decoder loss 0.961\n",
            "\n",
            "Epoch 373\n",
            "Critic training done in epoch 373\n",
            "Encoder decoder training done in epoch 373\n",
            "critic x loss -4.120 critic z loss -0.600 \n",
            "encoder loss 4.578 decoder loss 0.956\n",
            "\n",
            "Epoch 374\n",
            "Critic training done in epoch 374\n",
            "Encoder decoder training done in epoch 374\n",
            "critic x loss -4.127 critic z loss -0.603 \n",
            "encoder loss 4.586 decoder loss 0.962\n",
            "\n",
            "Epoch 375\n",
            "Critic training done in epoch 375\n",
            "Encoder decoder training done in epoch 375\n",
            "critic x loss -4.134 critic z loss -0.608 \n",
            "encoder loss 4.593 decoder loss 0.963\n",
            "\n",
            "Epoch 376\n",
            "Critic training done in epoch 376\n",
            "Encoder decoder training done in epoch 376\n",
            "critic x loss -4.140 critic z loss -0.607 \n",
            "encoder loss 4.601 decoder loss 0.957\n",
            "\n",
            "Epoch 377\n",
            "Critic training done in epoch 377\n",
            "Encoder decoder training done in epoch 377\n",
            "critic x loss -4.149 critic z loss -0.609 \n",
            "encoder loss 4.610 decoder loss 0.962\n",
            "\n",
            "Epoch 378\n",
            "Critic training done in epoch 378\n",
            "Encoder decoder training done in epoch 378\n",
            "critic x loss -4.155 critic z loss -0.608 \n",
            "encoder loss 4.615 decoder loss 0.955\n",
            "\n",
            "Epoch 379\n",
            "Critic training done in epoch 379\n",
            "Encoder decoder training done in epoch 379\n",
            "critic x loss -4.161 critic z loss -0.609 \n",
            "encoder loss 4.625 decoder loss 0.964\n",
            "\n",
            "Epoch 380\n",
            "Critic training done in epoch 380\n",
            "Encoder decoder training done in epoch 380\n",
            "critic x loss -4.170 critic z loss -0.609 \n",
            "encoder loss 4.631 decoder loss 0.963\n",
            "\n",
            "Epoch 381\n",
            "Critic training done in epoch 381\n",
            "Encoder decoder training done in epoch 381\n",
            "critic x loss -4.175 critic z loss -0.615 \n",
            "encoder loss 4.640 decoder loss 0.962\n",
            "\n",
            "Epoch 382\n",
            "Critic training done in epoch 382\n",
            "Encoder decoder training done in epoch 382\n",
            "critic x loss -4.183 critic z loss -0.615 \n",
            "encoder loss 4.645 decoder loss 0.954\n",
            "\n",
            "Epoch 383\n",
            "Critic training done in epoch 383\n",
            "Encoder decoder training done in epoch 383\n",
            "critic x loss -4.189 critic z loss -0.615 \n",
            "encoder loss 4.650 decoder loss 0.973\n",
            "\n",
            "Epoch 384\n",
            "Critic training done in epoch 384\n",
            "Encoder decoder training done in epoch 384\n",
            "critic x loss -4.196 critic z loss -0.614 \n",
            "encoder loss 4.657 decoder loss 0.969\n",
            "\n",
            "Epoch 385\n",
            "Critic training done in epoch 385\n",
            "Encoder decoder training done in epoch 385\n",
            "critic x loss -4.203 critic z loss -0.619 \n",
            "encoder loss 4.665 decoder loss 0.964\n",
            "\n",
            "Epoch 386\n",
            "Critic training done in epoch 386\n",
            "Encoder decoder training done in epoch 386\n",
            "critic x loss -4.209 critic z loss -0.619 \n",
            "encoder loss 4.671 decoder loss 0.965\n",
            "\n",
            "Epoch 387\n",
            "Critic training done in epoch 387\n",
            "Encoder decoder training done in epoch 387\n",
            "critic x loss -4.216 critic z loss -0.621 \n",
            "encoder loss 4.680 decoder loss 0.976\n",
            "\n",
            "Epoch 388\n",
            "Critic training done in epoch 388\n",
            "Encoder decoder training done in epoch 388\n",
            "critic x loss -4.221 critic z loss -0.622 \n",
            "encoder loss 4.686 decoder loss 0.970\n",
            "\n",
            "Epoch 389\n",
            "Critic training done in epoch 389\n",
            "Encoder decoder training done in epoch 389\n",
            "critic x loss -4.228 critic z loss -0.624 \n",
            "encoder loss 4.690 decoder loss 0.964\n",
            "\n",
            "Epoch 390\n",
            "Critic training done in epoch 390\n",
            "Encoder decoder training done in epoch 390\n",
            "critic x loss -4.234 critic z loss -0.623 \n",
            "encoder loss 4.697 decoder loss 0.980\n",
            "\n",
            "Epoch 391\n",
            "Critic training done in epoch 391\n",
            "Encoder decoder training done in epoch 391\n",
            "critic x loss -4.241 critic z loss -0.625 \n",
            "encoder loss 4.704 decoder loss 0.980\n",
            "\n",
            "Epoch 392\n",
            "Critic training done in epoch 392\n",
            "Encoder decoder training done in epoch 392\n",
            "critic x loss -4.248 critic z loss -0.628 \n",
            "encoder loss 4.712 decoder loss 0.970\n",
            "\n",
            "Epoch 393\n",
            "Critic training done in epoch 393\n",
            "Encoder decoder training done in epoch 393\n",
            "critic x loss -4.254 critic z loss -0.629 \n",
            "encoder loss 4.717 decoder loss 0.983\n",
            "\n",
            "Epoch 394\n",
            "Critic training done in epoch 394\n",
            "Encoder decoder training done in epoch 394\n",
            "critic x loss -4.260 critic z loss -0.624 \n",
            "encoder loss 4.723 decoder loss 0.972\n",
            "\n",
            "Epoch 395\n",
            "Critic training done in epoch 395\n",
            "Encoder decoder training done in epoch 395\n",
            "critic x loss -4.265 critic z loss -0.630 \n",
            "encoder loss 4.730 decoder loss 0.982\n",
            "\n",
            "Epoch 396\n",
            "Critic training done in epoch 396\n",
            "Encoder decoder training done in epoch 396\n",
            "critic x loss -4.271 critic z loss -0.632 \n",
            "encoder loss 4.737 decoder loss 0.977\n",
            "\n",
            "Epoch 397\n",
            "Critic training done in epoch 397\n",
            "Encoder decoder training done in epoch 397\n",
            "critic x loss -4.278 critic z loss -0.634 \n",
            "encoder loss 4.744 decoder loss 0.975\n",
            "\n",
            "Epoch 398\n",
            "Critic training done in epoch 398\n",
            "Encoder decoder training done in epoch 398\n",
            "critic x loss -4.283 critic z loss -0.635 \n",
            "encoder loss 4.748 decoder loss 0.979\n",
            "\n",
            "Epoch 399\n",
            "Critic training done in epoch 399\n",
            "Encoder decoder training done in epoch 399\n",
            "critic x loss -4.289 critic z loss -0.636 \n",
            "encoder loss 4.756 decoder loss 0.985\n",
            "\n",
            "Epoch 400\n",
            "Critic training done in epoch 400\n",
            "Encoder decoder training done in epoch 400\n",
            "critic x loss -4.296 critic z loss -0.637 \n",
            "encoder loss 4.760 decoder loss 0.983\n",
            "\n",
            "Epoch 401\n",
            "Critic training done in epoch 401\n",
            "Encoder decoder training done in epoch 401\n",
            "critic x loss -4.301 critic z loss -0.637 \n",
            "encoder loss 4.766 decoder loss 0.980\n",
            "\n",
            "Epoch 402\n",
            "Critic training done in epoch 402\n",
            "Encoder decoder training done in epoch 402\n",
            "critic x loss -4.306 critic z loss -0.638 \n",
            "encoder loss 4.773 decoder loss 0.982\n",
            "\n",
            "Epoch 403\n",
            "Critic training done in epoch 403\n",
            "Encoder decoder training done in epoch 403\n",
            "critic x loss -4.312 critic z loss -0.640 \n",
            "encoder loss 4.775 decoder loss 0.985\n",
            "\n",
            "Epoch 404\n",
            "Critic training done in epoch 404\n",
            "Encoder decoder training done in epoch 404\n",
            "critic x loss -4.317 critic z loss -0.644 \n",
            "encoder loss 4.787 decoder loss 0.993\n",
            "\n",
            "Epoch 405\n",
            "Critic training done in epoch 405\n",
            "Encoder decoder training done in epoch 405\n",
            "critic x loss -4.323 critic z loss -0.645 \n",
            "encoder loss 4.792 decoder loss 0.991\n",
            "\n",
            "Epoch 406\n",
            "Critic training done in epoch 406\n",
            "Encoder decoder training done in epoch 406\n",
            "critic x loss -4.328 critic z loss -0.646 \n",
            "encoder loss 4.797 decoder loss 0.994\n",
            "\n",
            "Epoch 407\n",
            "Critic training done in epoch 407\n",
            "Encoder decoder training done in epoch 407\n",
            "critic x loss -4.334 critic z loss -0.643 \n",
            "encoder loss 4.799 decoder loss 0.992\n",
            "\n",
            "Epoch 408\n",
            "Critic training done in epoch 408\n",
            "Encoder decoder training done in epoch 408\n",
            "critic x loss -4.339 critic z loss -0.648 \n",
            "encoder loss 4.805 decoder loss 0.998\n",
            "\n",
            "Epoch 409\n",
            "Critic training done in epoch 409\n",
            "Encoder decoder training done in epoch 409\n",
            "critic x loss -4.344 critic z loss -0.645 \n",
            "encoder loss 4.811 decoder loss 0.998\n",
            "\n",
            "Epoch 410\n",
            "Critic training done in epoch 410\n",
            "Encoder decoder training done in epoch 410\n",
            "critic x loss -4.350 critic z loss -0.651 \n",
            "encoder loss 4.821 decoder loss 0.992\n",
            "\n",
            "Epoch 411\n",
            "Critic training done in epoch 411\n",
            "Encoder decoder training done in epoch 411\n",
            "critic x loss -4.353 critic z loss -0.652 \n",
            "encoder loss 4.820 decoder loss 0.995\n",
            "\n",
            "Epoch 412\n",
            "Critic training done in epoch 412\n",
            "Encoder decoder training done in epoch 412\n",
            "critic x loss -4.361 critic z loss -0.650 \n",
            "encoder loss 4.826 decoder loss 0.996\n",
            "\n",
            "Epoch 413\n",
            "Critic training done in epoch 413\n",
            "Encoder decoder training done in epoch 413\n",
            "critic x loss -4.365 critic z loss -0.655 \n",
            "encoder loss 4.833 decoder loss 0.997\n",
            "\n",
            "Epoch 414\n",
            "Critic training done in epoch 414\n",
            "Encoder decoder training done in epoch 414\n",
            "critic x loss -4.369 critic z loss -0.653 \n",
            "encoder loss 4.838 decoder loss 1.003\n",
            "\n",
            "Epoch 415\n",
            "Critic training done in epoch 415\n",
            "Encoder decoder training done in epoch 415\n",
            "critic x loss -4.373 critic z loss -0.655 \n",
            "encoder loss 4.844 decoder loss 0.998\n",
            "\n",
            "Epoch 416\n",
            "Critic training done in epoch 416\n",
            "Encoder decoder training done in epoch 416\n",
            "critic x loss -4.378 critic z loss -0.659 \n",
            "encoder loss 4.848 decoder loss 1.005\n",
            "\n",
            "Epoch 417\n",
            "Critic training done in epoch 417\n",
            "Encoder decoder training done in epoch 417\n",
            "critic x loss -4.384 critic z loss -0.657 \n",
            "encoder loss 4.854 decoder loss 0.997\n",
            "\n",
            "Epoch 418\n",
            "Critic training done in epoch 418\n",
            "Encoder decoder training done in epoch 418\n",
            "critic x loss -4.387 critic z loss -0.662 \n",
            "encoder loss 4.857 decoder loss 1.002\n",
            "\n",
            "Epoch 419\n",
            "Critic training done in epoch 419\n",
            "Encoder decoder training done in epoch 419\n",
            "critic x loss -4.393 critic z loss -0.658 \n",
            "encoder loss 4.864 decoder loss 1.001\n",
            "\n",
            "Epoch 420\n",
            "Critic training done in epoch 420\n",
            "Encoder decoder training done in epoch 420\n",
            "critic x loss -4.396 critic z loss -0.661 \n",
            "encoder loss 4.864 decoder loss 1.007\n",
            "\n",
            "Epoch 421\n",
            "Critic training done in epoch 421\n",
            "Encoder decoder training done in epoch 421\n",
            "critic x loss -4.400 critic z loss -0.664 \n",
            "encoder loss 4.871 decoder loss 1.005\n",
            "\n",
            "Epoch 422\n",
            "Critic training done in epoch 422\n",
            "Encoder decoder training done in epoch 422\n",
            "critic x loss -4.407 critic z loss -0.667 \n",
            "encoder loss 4.874 decoder loss 1.021\n",
            "\n",
            "Epoch 423\n",
            "Critic training done in epoch 423\n",
            "Encoder decoder training done in epoch 423\n",
            "critic x loss -4.410 critic z loss -0.667 \n",
            "encoder loss 4.882 decoder loss 1.003\n",
            "\n",
            "Epoch 424\n",
            "Critic training done in epoch 424\n",
            "Encoder decoder training done in epoch 424\n",
            "critic x loss -4.415 critic z loss -0.669 \n",
            "encoder loss 4.883 decoder loss 1.004\n",
            "\n",
            "Epoch 425\n",
            "Critic training done in epoch 425\n",
            "Encoder decoder training done in epoch 425\n",
            "critic x loss -4.419 critic z loss -0.665 \n",
            "encoder loss 4.888 decoder loss 1.010\n",
            "\n",
            "Epoch 426\n",
            "Critic training done in epoch 426\n",
            "Encoder decoder training done in epoch 426\n",
            "critic x loss -4.423 critic z loss -0.670 \n",
            "encoder loss 4.895 decoder loss 1.014\n",
            "\n",
            "Epoch 427\n",
            "Critic training done in epoch 427\n",
            "Encoder decoder training done in epoch 427\n",
            "critic x loss -4.428 critic z loss -0.672 \n",
            "encoder loss 4.903 decoder loss 1.014\n",
            "\n",
            "Epoch 428\n",
            "Critic training done in epoch 428\n",
            "Encoder decoder training done in epoch 428\n",
            "critic x loss -4.430 critic z loss -0.671 \n",
            "encoder loss 4.904 decoder loss 1.011\n",
            "\n",
            "Epoch 429\n",
            "Critic training done in epoch 429\n",
            "Encoder decoder training done in epoch 429\n",
            "critic x loss -4.435 critic z loss -0.674 \n",
            "encoder loss 4.907 decoder loss 1.007\n",
            "\n",
            "Epoch 430\n",
            "Critic training done in epoch 430\n",
            "Encoder decoder training done in epoch 430\n",
            "critic x loss -4.439 critic z loss -0.677 \n",
            "encoder loss 4.908 decoder loss 1.018\n",
            "\n",
            "Epoch 431\n",
            "Critic training done in epoch 431\n",
            "Encoder decoder training done in epoch 431\n",
            "critic x loss -4.441 critic z loss -0.675 \n",
            "encoder loss 4.914 decoder loss 1.011\n",
            "\n",
            "Epoch 432\n",
            "Critic training done in epoch 432\n",
            "Encoder decoder training done in epoch 432\n",
            "critic x loss -4.447 critic z loss -0.680 \n",
            "encoder loss 4.916 decoder loss 1.021\n",
            "\n",
            "Epoch 433\n",
            "Critic training done in epoch 433\n",
            "Encoder decoder training done in epoch 433\n",
            "critic x loss -4.449 critic z loss -0.681 \n",
            "encoder loss 4.920 decoder loss 1.019\n",
            "\n",
            "Epoch 434\n",
            "Critic training done in epoch 434\n",
            "Encoder decoder training done in epoch 434\n",
            "critic x loss -4.454 critic z loss -0.680 \n",
            "encoder loss 4.926 decoder loss 1.018\n",
            "\n",
            "Epoch 435\n",
            "Critic training done in epoch 435\n",
            "Encoder decoder training done in epoch 435\n",
            "critic x loss -4.456 critic z loss -0.680 \n",
            "encoder loss 4.930 decoder loss 1.018\n",
            "\n",
            "Epoch 436\n",
            "Critic training done in epoch 436\n",
            "Encoder decoder training done in epoch 436\n",
            "critic x loss -4.459 critic z loss -0.685 \n",
            "encoder loss 4.933 decoder loss 1.025\n",
            "\n",
            "Epoch 437\n",
            "Critic training done in epoch 437\n",
            "Encoder decoder training done in epoch 437\n",
            "critic x loss -4.463 critic z loss -0.687 \n",
            "encoder loss 4.939 decoder loss 1.019\n",
            "\n",
            "Epoch 438\n",
            "Critic training done in epoch 438\n",
            "Encoder decoder training done in epoch 438\n",
            "critic x loss -4.468 critic z loss -0.685 \n",
            "encoder loss 4.940 decoder loss 1.025\n",
            "\n",
            "Epoch 439\n",
            "Critic training done in epoch 439\n",
            "Encoder decoder training done in epoch 439\n",
            "critic x loss -4.471 critic z loss -0.686 \n",
            "encoder loss 4.943 decoder loss 1.027\n",
            "\n",
            "Epoch 440\n",
            "Critic training done in epoch 440\n",
            "Encoder decoder training done in epoch 440\n",
            "critic x loss -4.472 critic z loss -0.686 \n",
            "encoder loss 4.946 decoder loss 1.032\n",
            "\n",
            "Epoch 441\n",
            "Critic training done in epoch 441\n",
            "Encoder decoder training done in epoch 441\n",
            "critic x loss -4.476 critic z loss -0.686 \n",
            "encoder loss 4.951 decoder loss 1.022\n",
            "\n",
            "Epoch 442\n",
            "Critic training done in epoch 442\n",
            "Encoder decoder training done in epoch 442\n",
            "critic x loss -4.480 critic z loss -0.691 \n",
            "encoder loss 4.952 decoder loss 1.028\n",
            "\n",
            "Epoch 443\n",
            "Critic training done in epoch 443\n",
            "Encoder decoder training done in epoch 443\n",
            "critic x loss -4.483 critic z loss -0.690 \n",
            "encoder loss 4.954 decoder loss 1.025\n",
            "\n",
            "Epoch 444\n",
            "Critic training done in epoch 444\n",
            "Encoder decoder training done in epoch 444\n",
            "critic x loss -4.485 critic z loss -0.691 \n",
            "encoder loss 4.959 decoder loss 1.017\n",
            "\n",
            "Epoch 445\n",
            "Critic training done in epoch 445\n",
            "Encoder decoder training done in epoch 445\n",
            "critic x loss -4.487 critic z loss -0.692 \n",
            "encoder loss 4.962 decoder loss 1.025\n",
            "\n",
            "Epoch 446\n",
            "Critic training done in epoch 446\n",
            "Encoder decoder training done in epoch 446\n",
            "critic x loss -4.491 critic z loss -0.693 \n",
            "encoder loss 4.965 decoder loss 1.028\n",
            "\n",
            "Epoch 447\n",
            "Critic training done in epoch 447\n",
            "Encoder decoder training done in epoch 447\n",
            "critic x loss -4.496 critic z loss -0.693 \n",
            "encoder loss 4.966 decoder loss 1.028\n",
            "\n",
            "Epoch 448\n",
            "Critic training done in epoch 448\n",
            "Encoder decoder training done in epoch 448\n",
            "critic x loss -4.496 critic z loss -0.697 \n",
            "encoder loss 4.968 decoder loss 1.026\n",
            "\n",
            "Epoch 449\n",
            "Critic training done in epoch 449\n",
            "Encoder decoder training done in epoch 449\n",
            "critic x loss -4.500 critic z loss -0.698 \n",
            "encoder loss 4.974 decoder loss 1.035\n",
            "\n",
            "Epoch 450\n",
            "Critic training done in epoch 450\n",
            "Encoder decoder training done in epoch 450\n",
            "critic x loss -4.501 critic z loss -0.699 \n",
            "encoder loss 4.977 decoder loss 1.040\n",
            "\n",
            "Epoch 451\n",
            "Critic training done in epoch 451\n",
            "Encoder decoder training done in epoch 451\n",
            "critic x loss -4.504 critic z loss -0.699 \n",
            "encoder loss 4.978 decoder loss 1.035\n",
            "\n",
            "Epoch 452\n",
            "Critic training done in epoch 452\n",
            "Encoder decoder training done in epoch 452\n",
            "critic x loss -4.509 critic z loss -0.702 \n",
            "encoder loss 4.980 decoder loss 1.042\n",
            "\n",
            "Epoch 453\n",
            "Critic training done in epoch 453\n",
            "Encoder decoder training done in epoch 453\n",
            "critic x loss -4.508 critic z loss -0.702 \n",
            "encoder loss 4.981 decoder loss 1.040\n",
            "\n",
            "Epoch 454\n",
            "Critic training done in epoch 454\n",
            "Encoder decoder training done in epoch 454\n",
            "critic x loss -4.512 critic z loss -0.708 \n",
            "encoder loss 4.988 decoder loss 1.035\n",
            "\n",
            "Epoch 455\n",
            "Critic training done in epoch 455\n",
            "Encoder decoder training done in epoch 455\n",
            "critic x loss -4.514 critic z loss -0.707 \n",
            "encoder loss 4.988 decoder loss 1.041\n",
            "\n",
            "Epoch 456\n",
            "Critic training done in epoch 456\n",
            "Encoder decoder training done in epoch 456\n",
            "critic x loss -4.516 critic z loss -0.710 \n",
            "encoder loss 4.993 decoder loss 1.043\n",
            "\n",
            "Epoch 457\n",
            "Critic training done in epoch 457\n",
            "Encoder decoder training done in epoch 457\n",
            "critic x loss -4.517 critic z loss -0.709 \n",
            "encoder loss 4.991 decoder loss 1.036\n",
            "\n",
            "Epoch 458\n",
            "Critic training done in epoch 458\n",
            "Encoder decoder training done in epoch 458\n",
            "critic x loss -4.521 critic z loss -0.710 \n",
            "encoder loss 4.996 decoder loss 1.047\n",
            "\n",
            "Epoch 459\n",
            "Critic training done in epoch 459\n",
            "Encoder decoder training done in epoch 459\n",
            "critic x loss -4.519 critic z loss -0.711 \n",
            "encoder loss 4.999 decoder loss 1.044\n",
            "\n",
            "Epoch 460\n",
            "Critic training done in epoch 460\n",
            "Encoder decoder training done in epoch 460\n",
            "critic x loss -4.524 critic z loss -0.710 \n",
            "encoder loss 4.997 decoder loss 1.043\n",
            "\n",
            "Epoch 461\n",
            "Critic training done in epoch 461\n",
            "Encoder decoder training done in epoch 461\n",
            "critic x loss -4.524 critic z loss -0.712 \n",
            "encoder loss 5.005 decoder loss 1.044\n",
            "\n",
            "Epoch 462\n",
            "Critic training done in epoch 462\n",
            "Encoder decoder training done in epoch 462\n",
            "critic x loss -4.526 critic z loss -0.713 \n",
            "encoder loss 4.998 decoder loss 1.052\n",
            "\n",
            "Epoch 463\n",
            "Critic training done in epoch 463\n",
            "Encoder decoder training done in epoch 463\n",
            "critic x loss -4.527 critic z loss -0.715 \n",
            "encoder loss 5.001 decoder loss 1.049\n",
            "\n",
            "Epoch 464\n",
            "Critic training done in epoch 464\n",
            "Encoder decoder training done in epoch 464\n",
            "critic x loss -4.529 critic z loss -0.715 \n",
            "encoder loss 5.005 decoder loss 1.054\n",
            "\n",
            "Epoch 465\n",
            "Critic training done in epoch 465\n",
            "Encoder decoder training done in epoch 465\n",
            "critic x loss -4.530 critic z loss -0.718 \n",
            "encoder loss 5.008 decoder loss 1.045\n",
            "\n",
            "Epoch 466\n",
            "Critic training done in epoch 466\n",
            "Encoder decoder training done in epoch 466\n",
            "critic x loss -4.532 critic z loss -0.719 \n",
            "encoder loss 5.004 decoder loss 1.048\n",
            "\n",
            "Epoch 467\n",
            "Critic training done in epoch 467\n",
            "Encoder decoder training done in epoch 467\n",
            "critic x loss -4.536 critic z loss -0.721 \n",
            "encoder loss 5.005 decoder loss 1.052\n",
            "\n",
            "Epoch 468\n",
            "Critic training done in epoch 468\n",
            "Encoder decoder training done in epoch 468\n",
            "critic x loss -4.535 critic z loss -0.719 \n",
            "encoder loss 5.016 decoder loss 1.051\n",
            "\n",
            "Epoch 469\n",
            "Critic training done in epoch 469\n",
            "Encoder decoder training done in epoch 469\n",
            "critic x loss -4.537 critic z loss -0.723 \n",
            "encoder loss 5.013 decoder loss 1.054\n",
            "\n",
            "Epoch 470\n",
            "Critic training done in epoch 470\n",
            "Encoder decoder training done in epoch 470\n",
            "critic x loss -4.537 critic z loss -0.729 \n",
            "encoder loss 5.015 decoder loss 1.060\n",
            "\n",
            "Epoch 471\n",
            "Critic training done in epoch 471\n",
            "Encoder decoder training done in epoch 471\n",
            "critic x loss -4.538 critic z loss -0.726 \n",
            "encoder loss 5.014 decoder loss 1.058\n",
            "\n",
            "Epoch 472\n",
            "Critic training done in epoch 472\n",
            "Encoder decoder training done in epoch 472\n",
            "critic x loss -4.540 critic z loss -0.728 \n",
            "encoder loss 5.016 decoder loss 1.057\n",
            "\n",
            "Epoch 473\n",
            "Critic training done in epoch 473\n",
            "Encoder decoder training done in epoch 473\n",
            "critic x loss -4.541 critic z loss -0.723 \n",
            "encoder loss 5.019 decoder loss 1.061\n",
            "\n",
            "Epoch 474\n",
            "Critic training done in epoch 474\n",
            "Encoder decoder training done in epoch 474\n",
            "critic x loss -4.542 critic z loss -0.730 \n",
            "encoder loss 5.019 decoder loss 1.052\n",
            "\n",
            "Epoch 475\n",
            "Critic training done in epoch 475\n",
            "Encoder decoder training done in epoch 475\n",
            "critic x loss -4.542 critic z loss -0.728 \n",
            "encoder loss 5.019 decoder loss 1.058\n",
            "\n",
            "Epoch 476\n",
            "Critic training done in epoch 476\n",
            "Encoder decoder training done in epoch 476\n",
            "critic x loss -4.542 critic z loss -0.733 \n",
            "encoder loss 5.020 decoder loss 1.067\n",
            "\n",
            "Epoch 477\n",
            "Critic training done in epoch 477\n",
            "Encoder decoder training done in epoch 477\n",
            "critic x loss -4.541 critic z loss -0.728 \n",
            "encoder loss 5.024 decoder loss 1.062\n",
            "\n",
            "Epoch 478\n",
            "Critic training done in epoch 478\n",
            "Encoder decoder training done in epoch 478\n",
            "critic x loss -4.544 critic z loss -0.734 \n",
            "encoder loss 5.027 decoder loss 1.064\n",
            "\n",
            "Epoch 479\n",
            "Critic training done in epoch 479\n",
            "Encoder decoder training done in epoch 479\n",
            "critic x loss -4.544 critic z loss -0.732 \n",
            "encoder loss 5.018 decoder loss 1.068\n",
            "\n",
            "Epoch 480\n",
            "Critic training done in epoch 480\n",
            "Encoder decoder training done in epoch 480\n",
            "critic x loss -4.544 critic z loss -0.733 \n",
            "encoder loss 5.023 decoder loss 1.065\n",
            "\n",
            "Epoch 481\n",
            "Critic training done in epoch 481\n",
            "Encoder decoder training done in epoch 481\n",
            "critic x loss -4.544 critic z loss -0.736 \n",
            "encoder loss 5.019 decoder loss 1.057\n",
            "\n",
            "Epoch 482\n",
            "Critic training done in epoch 482\n",
            "Encoder decoder training done in epoch 482\n",
            "critic x loss -4.546 critic z loss -0.733 \n",
            "encoder loss 5.020 decoder loss 1.063\n",
            "\n",
            "Epoch 483\n",
            "Critic training done in epoch 483\n",
            "Encoder decoder training done in epoch 483\n",
            "critic x loss -4.544 critic z loss -0.738 \n",
            "encoder loss 5.026 decoder loss 1.061\n",
            "\n",
            "Epoch 484\n",
            "Critic training done in epoch 484\n",
            "Encoder decoder training done in epoch 484\n",
            "critic x loss -4.545 critic z loss -0.742 \n",
            "encoder loss 5.021 decoder loss 1.056\n",
            "\n",
            "Epoch 485\n",
            "Critic training done in epoch 485\n",
            "Encoder decoder training done in epoch 485\n",
            "critic x loss -4.547 critic z loss -0.745 \n",
            "encoder loss 5.026 decoder loss 1.065\n",
            "\n",
            "Epoch 486\n",
            "Critic training done in epoch 486\n",
            "Encoder decoder training done in epoch 486\n",
            "critic x loss -4.545 critic z loss -0.742 \n",
            "encoder loss 5.024 decoder loss 1.069\n",
            "\n",
            "Epoch 487\n",
            "Critic training done in epoch 487\n",
            "Encoder decoder training done in epoch 487\n",
            "critic x loss -4.546 critic z loss -0.745 \n",
            "encoder loss 5.022 decoder loss 1.065\n",
            "\n",
            "Epoch 488\n",
            "Critic training done in epoch 488\n",
            "Encoder decoder training done in epoch 488\n",
            "critic x loss -4.545 critic z loss -0.747 \n",
            "encoder loss 5.019 decoder loss 1.060\n",
            "\n",
            "Epoch 489\n",
            "Critic training done in epoch 489\n",
            "Encoder decoder training done in epoch 489\n",
            "critic x loss -4.542 critic z loss -0.746 \n",
            "encoder loss 5.024 decoder loss 1.066\n",
            "\n",
            "Epoch 490\n",
            "Critic training done in epoch 490\n",
            "Encoder decoder training done in epoch 490\n",
            "critic x loss -4.544 critic z loss -0.749 \n",
            "encoder loss 5.017 decoder loss 1.065\n",
            "\n",
            "Epoch 491\n",
            "Critic training done in epoch 491\n",
            "Encoder decoder training done in epoch 491\n",
            "critic x loss -4.544 critic z loss -0.745 \n",
            "encoder loss 5.023 decoder loss 1.077\n",
            "\n",
            "Epoch 492\n",
            "Critic training done in epoch 492\n",
            "Encoder decoder training done in epoch 492\n",
            "critic x loss -4.544 critic z loss -0.746 \n",
            "encoder loss 5.022 decoder loss 1.078\n",
            "\n",
            "Epoch 493\n",
            "Critic training done in epoch 493\n",
            "Encoder decoder training done in epoch 493\n",
            "critic x loss -4.544 critic z loss -0.746 \n",
            "encoder loss 5.024 decoder loss 1.080\n",
            "\n",
            "Epoch 494\n",
            "Critic training done in epoch 494\n",
            "Encoder decoder training done in epoch 494\n",
            "critic x loss -4.542 critic z loss -0.750 \n",
            "encoder loss 5.025 decoder loss 1.074\n",
            "\n",
            "Epoch 495\n",
            "Critic training done in epoch 495\n",
            "Encoder decoder training done in epoch 495\n",
            "critic x loss -4.543 critic z loss -0.750 \n",
            "encoder loss 5.023 decoder loss 1.082\n",
            "\n",
            "Epoch 496\n",
            "Critic training done in epoch 496\n",
            "Encoder decoder training done in epoch 496\n",
            "critic x loss -4.543 critic z loss -0.754 \n",
            "encoder loss 5.014 decoder loss 1.076\n",
            "\n",
            "Epoch 497\n",
            "Critic training done in epoch 497\n",
            "Encoder decoder training done in epoch 497\n",
            "critic x loss -4.540 critic z loss -0.754 \n",
            "encoder loss 5.014 decoder loss 1.076\n",
            "\n",
            "Epoch 498\n",
            "Critic training done in epoch 498\n",
            "Encoder decoder training done in epoch 498\n",
            "critic x loss -4.543 critic z loss -0.755 \n",
            "encoder loss 5.013 decoder loss 1.075\n",
            "\n",
            "Epoch 499\n",
            "Critic training done in epoch 499\n",
            "Encoder decoder training done in epoch 499\n",
            "critic x loss -4.537 critic z loss -0.754 \n",
            "encoder loss 5.012 decoder loss 1.083\n",
            "\n",
            "Epoch 500\n",
            "Critic training done in epoch 500\n",
            "Encoder decoder training done in epoch 500\n",
            "critic x loss -4.540 critic z loss -0.757 \n",
            "encoder loss 5.014 decoder loss 1.076\n",
            "\n",
            "Epoch 501\n",
            "Critic training done in epoch 501\n",
            "Encoder decoder training done in epoch 501\n",
            "critic x loss -4.535 critic z loss -0.761 \n",
            "encoder loss 5.011 decoder loss 1.086\n",
            "\n",
            "Epoch 502\n",
            "Critic training done in epoch 502\n",
            "Encoder decoder training done in epoch 502\n",
            "critic x loss -4.534 critic z loss -0.761 \n",
            "encoder loss 5.012 decoder loss 1.076\n",
            "\n",
            "Epoch 503\n",
            "Critic training done in epoch 503\n",
            "Encoder decoder training done in epoch 503\n",
            "critic x loss -4.533 critic z loss -0.759 \n",
            "encoder loss 5.005 decoder loss 1.087\n",
            "\n",
            "Epoch 504\n",
            "Critic training done in epoch 504\n",
            "Encoder decoder training done in epoch 504\n",
            "critic x loss -4.532 critic z loss -0.760 \n",
            "encoder loss 5.012 decoder loss 1.086\n",
            "\n",
            "Epoch 505\n",
            "Critic training done in epoch 505\n",
            "Encoder decoder training done in epoch 505\n",
            "critic x loss -4.531 critic z loss -0.763 \n",
            "encoder loss 5.010 decoder loss 1.081\n",
            "\n",
            "Epoch 506\n",
            "Critic training done in epoch 506\n",
            "Encoder decoder training done in epoch 506\n",
            "critic x loss -4.529 critic z loss -0.767 \n",
            "encoder loss 5.006 decoder loss 1.077\n",
            "\n",
            "Epoch 507\n",
            "Critic training done in epoch 507\n",
            "Encoder decoder training done in epoch 507\n",
            "critic x loss -4.527 critic z loss -0.765 \n",
            "encoder loss 5.007 decoder loss 1.086\n",
            "\n",
            "Epoch 508\n",
            "Critic training done in epoch 508\n",
            "Encoder decoder training done in epoch 508\n",
            "critic x loss -4.526 critic z loss -0.765 \n",
            "encoder loss 5.004 decoder loss 1.091\n",
            "\n",
            "Epoch 509\n",
            "Critic training done in epoch 509\n",
            "Encoder decoder training done in epoch 509\n",
            "critic x loss -4.524 critic z loss -0.770 \n",
            "encoder loss 5.002 decoder loss 1.089\n",
            "\n",
            "Epoch 510\n",
            "Critic training done in epoch 510\n",
            "Encoder decoder training done in epoch 510\n",
            "critic x loss -4.524 critic z loss -0.766 \n",
            "encoder loss 4.995 decoder loss 1.088\n",
            "\n",
            "Epoch 511\n",
            "Critic training done in epoch 511\n",
            "Encoder decoder training done in epoch 511\n",
            "critic x loss -4.521 critic z loss -0.770 \n",
            "encoder loss 5.003 decoder loss 1.085\n",
            "\n",
            "Epoch 512\n",
            "Critic training done in epoch 512\n",
            "Encoder decoder training done in epoch 512\n",
            "critic x loss -4.520 critic z loss -0.768 \n",
            "encoder loss 4.993 decoder loss 1.084\n",
            "\n",
            "Epoch 513\n",
            "Critic training done in epoch 513\n",
            "Encoder decoder training done in epoch 513\n",
            "critic x loss -4.517 critic z loss -0.771 \n",
            "encoder loss 4.993 decoder loss 1.087\n",
            "\n",
            "Epoch 514\n",
            "Critic training done in epoch 514\n",
            "Encoder decoder training done in epoch 514\n",
            "critic x loss -4.514 critic z loss -0.775 \n",
            "encoder loss 4.992 decoder loss 1.082\n",
            "\n",
            "Epoch 515\n",
            "Critic training done in epoch 515\n",
            "Encoder decoder training done in epoch 515\n",
            "critic x loss -4.516 critic z loss -0.774 \n",
            "encoder loss 4.982 decoder loss 1.086\n",
            "\n",
            "Epoch 516\n",
            "Critic training done in epoch 516\n",
            "Encoder decoder training done in epoch 516\n",
            "critic x loss -4.514 critic z loss -0.773 \n",
            "encoder loss 4.989 decoder loss 1.094\n",
            "\n",
            "Epoch 517\n",
            "Critic training done in epoch 517\n",
            "Encoder decoder training done in epoch 517\n",
            "critic x loss -4.508 critic z loss -0.776 \n",
            "encoder loss 4.987 decoder loss 1.091\n",
            "\n",
            "Epoch 518\n",
            "Critic training done in epoch 518\n",
            "Encoder decoder training done in epoch 518\n",
            "critic x loss -4.506 critic z loss -0.778 \n",
            "encoder loss 4.982 decoder loss 1.091\n",
            "\n",
            "Epoch 519\n",
            "Critic training done in epoch 519\n",
            "Encoder decoder training done in epoch 519\n",
            "critic x loss -4.503 critic z loss -0.779 \n",
            "encoder loss 4.974 decoder loss 1.090\n",
            "\n",
            "Epoch 520\n",
            "Critic training done in epoch 520\n",
            "Encoder decoder training done in epoch 520\n",
            "critic x loss -4.502 critic z loss -0.783 \n",
            "encoder loss 4.980 decoder loss 1.090\n",
            "\n",
            "Epoch 521\n",
            "Critic training done in epoch 521\n",
            "Encoder decoder training done in epoch 521\n",
            "critic x loss -4.500 critic z loss -0.780 \n",
            "encoder loss 4.979 decoder loss 1.094\n",
            "\n",
            "Epoch 522\n",
            "Critic training done in epoch 522\n",
            "Encoder decoder training done in epoch 522\n",
            "critic x loss -4.497 critic z loss -0.782 \n",
            "encoder loss 4.970 decoder loss 1.093\n",
            "\n",
            "Epoch 523\n",
            "Critic training done in epoch 523\n",
            "Encoder decoder training done in epoch 523\n",
            "critic x loss -4.494 critic z loss -0.783 \n",
            "encoder loss 4.973 decoder loss 1.101\n",
            "\n",
            "Epoch 524\n",
            "Critic training done in epoch 524\n",
            "Encoder decoder training done in epoch 524\n",
            "critic x loss -4.492 critic z loss -0.784 \n",
            "encoder loss 4.966 decoder loss 1.097\n",
            "\n",
            "Epoch 525\n",
            "Critic training done in epoch 525\n",
            "Encoder decoder training done in epoch 525\n",
            "critic x loss -4.486 critic z loss -0.784 \n",
            "encoder loss 4.966 decoder loss 1.098\n",
            "\n",
            "Epoch 526\n",
            "Critic training done in epoch 526\n",
            "Encoder decoder training done in epoch 526\n",
            "critic x loss -4.484 critic z loss -0.785 \n",
            "encoder loss 4.964 decoder loss 1.091\n",
            "\n",
            "Epoch 527\n",
            "Critic training done in epoch 527\n",
            "Encoder decoder training done in epoch 527\n",
            "critic x loss -4.483 critic z loss -0.788 \n",
            "encoder loss 4.964 decoder loss 1.097\n",
            "\n",
            "Epoch 528\n",
            "Critic training done in epoch 528\n",
            "Encoder decoder training done in epoch 528\n",
            "critic x loss -4.476 critic z loss -0.789 \n",
            "encoder loss 4.954 decoder loss 1.104\n",
            "\n",
            "Epoch 529\n",
            "Critic training done in epoch 529\n",
            "Encoder decoder training done in epoch 529\n",
            "critic x loss -4.477 critic z loss -0.788 \n",
            "encoder loss 4.953 decoder loss 1.107\n",
            "\n",
            "Epoch 530\n",
            "Critic training done in epoch 530\n",
            "Encoder decoder training done in epoch 530\n",
            "critic x loss -4.471 critic z loss -0.791 \n",
            "encoder loss 4.942 decoder loss 1.108\n",
            "\n",
            "Epoch 531\n",
            "Critic training done in epoch 531\n",
            "Encoder decoder training done in epoch 531\n",
            "critic x loss -4.470 critic z loss -0.790 \n",
            "encoder loss 4.937 decoder loss 1.095\n",
            "\n",
            "Epoch 532\n",
            "Critic training done in epoch 532\n",
            "Encoder decoder training done in epoch 532\n",
            "critic x loss -4.465 critic z loss -0.792 \n",
            "encoder loss 4.941 decoder loss 1.099\n",
            "\n",
            "Epoch 533\n",
            "Critic training done in epoch 533\n",
            "Encoder decoder training done in epoch 533\n",
            "critic x loss -4.464 critic z loss -0.794 \n",
            "encoder loss 4.939 decoder loss 1.099\n",
            "\n",
            "Epoch 534\n",
            "Critic training done in epoch 534\n",
            "Encoder decoder training done in epoch 534\n",
            "critic x loss -4.462 critic z loss -0.793 \n",
            "encoder loss 4.929 decoder loss 1.100\n",
            "\n",
            "Epoch 535\n",
            "Critic training done in epoch 535\n",
            "Encoder decoder training done in epoch 535\n",
            "critic x loss -4.459 critic z loss -0.793 \n",
            "encoder loss 4.929 decoder loss 1.101\n",
            "\n",
            "Epoch 536\n",
            "Critic training done in epoch 536\n",
            "Encoder decoder training done in epoch 536\n",
            "critic x loss -4.455 critic z loss -0.797 \n",
            "encoder loss 4.924 decoder loss 1.110\n",
            "\n",
            "Epoch 537\n",
            "Critic training done in epoch 537\n",
            "Encoder decoder training done in epoch 537\n",
            "critic x loss -4.445 critic z loss -0.797 \n",
            "encoder loss 4.923 decoder loss 1.109\n",
            "\n",
            "Epoch 538\n",
            "Critic training done in epoch 538\n",
            "Encoder decoder training done in epoch 538\n",
            "critic x loss -4.444 critic z loss -0.798 \n",
            "encoder loss 4.919 decoder loss 1.109\n",
            "\n",
            "Epoch 539\n",
            "Critic training done in epoch 539\n",
            "Encoder decoder training done in epoch 539\n",
            "critic x loss -4.439 critic z loss -0.802 \n",
            "encoder loss 4.914 decoder loss 1.099\n",
            "\n",
            "Epoch 540\n",
            "Critic training done in epoch 540\n",
            "Encoder decoder training done in epoch 540\n",
            "critic x loss -4.437 critic z loss -0.801 \n",
            "encoder loss 4.911 decoder loss 1.115\n",
            "\n",
            "Epoch 541\n",
            "Critic training done in epoch 541\n",
            "Encoder decoder training done in epoch 541\n",
            "critic x loss -4.431 critic z loss -0.804 \n",
            "encoder loss 4.910 decoder loss 1.112\n",
            "\n",
            "Epoch 542\n",
            "Critic training done in epoch 542\n",
            "Encoder decoder training done in epoch 542\n",
            "critic x loss -4.431 critic z loss -0.803 \n",
            "encoder loss 4.901 decoder loss 1.118\n",
            "\n",
            "Epoch 543\n",
            "Critic training done in epoch 543\n",
            "Encoder decoder training done in epoch 543\n",
            "critic x loss -4.425 critic z loss -0.805 \n",
            "encoder loss 4.899 decoder loss 1.111\n",
            "\n",
            "Epoch 544\n",
            "Critic training done in epoch 544\n",
            "Encoder decoder training done in epoch 544\n",
            "critic x loss -4.421 critic z loss -0.807 \n",
            "encoder loss 4.895 decoder loss 1.111\n",
            "\n",
            "Epoch 545\n",
            "Critic training done in epoch 545\n",
            "Encoder decoder training done in epoch 545\n",
            "critic x loss -4.417 critic z loss -0.807 \n",
            "encoder loss 4.888 decoder loss 1.108\n",
            "\n",
            "Epoch 546\n",
            "Critic training done in epoch 546\n",
            "Encoder decoder training done in epoch 546\n",
            "critic x loss -4.413 critic z loss -0.807 \n",
            "encoder loss 4.898 decoder loss 1.116\n",
            "\n",
            "Epoch 547\n",
            "Critic training done in epoch 547\n",
            "Encoder decoder training done in epoch 547\n",
            "critic x loss -4.411 critic z loss -0.811 \n",
            "encoder loss 4.889 decoder loss 1.107\n",
            "\n",
            "Epoch 548\n",
            "Critic training done in epoch 548\n",
            "Encoder decoder training done in epoch 548\n",
            "critic x loss -4.401 critic z loss -0.809 \n",
            "encoder loss 4.877 decoder loss 1.113\n",
            "\n",
            "Epoch 549\n",
            "Critic training done in epoch 549\n",
            "Encoder decoder training done in epoch 549\n",
            "critic x loss -4.399 critic z loss -0.811 \n",
            "encoder loss 4.870 decoder loss 1.111\n",
            "\n",
            "Epoch 550\n",
            "Critic training done in epoch 550\n",
            "Encoder decoder training done in epoch 550\n",
            "critic x loss -4.394 critic z loss -0.810 \n",
            "encoder loss 4.870 decoder loss 1.115\n",
            "\n",
            "Epoch 551\n",
            "Critic training done in epoch 551\n",
            "Encoder decoder training done in epoch 551\n",
            "critic x loss -4.385 critic z loss -0.812 \n",
            "encoder loss 4.857 decoder loss 1.124\n",
            "\n",
            "Epoch 552\n",
            "Critic training done in epoch 552\n",
            "Encoder decoder training done in epoch 552\n",
            "critic x loss -4.383 critic z loss -0.815 \n",
            "encoder loss 4.859 decoder loss 1.115\n",
            "\n",
            "Epoch 553\n",
            "Critic training done in epoch 553\n",
            "Encoder decoder training done in epoch 553\n",
            "critic x loss -4.380 critic z loss -0.813 \n",
            "encoder loss 4.846 decoder loss 1.116\n",
            "\n",
            "Epoch 554\n",
            "Critic training done in epoch 554\n",
            "Encoder decoder training done in epoch 554\n",
            "critic x loss -4.375 critic z loss -0.818 \n",
            "encoder loss 4.845 decoder loss 1.128\n",
            "\n",
            "Epoch 555\n",
            "Critic training done in epoch 555\n",
            "Encoder decoder training done in epoch 555\n",
            "critic x loss -4.373 critic z loss -0.813 \n",
            "encoder loss 4.839 decoder loss 1.121\n",
            "\n",
            "Epoch 556\n",
            "Critic training done in epoch 556\n",
            "Encoder decoder training done in epoch 556\n",
            "critic x loss -4.363 critic z loss -0.818 \n",
            "encoder loss 4.837 decoder loss 1.126\n",
            "\n",
            "Epoch 557\n",
            "Critic training done in epoch 557\n",
            "Encoder decoder training done in epoch 557\n",
            "critic x loss -4.361 critic z loss -0.818 \n",
            "encoder loss 4.824 decoder loss 1.117\n",
            "\n",
            "Epoch 558\n",
            "Critic training done in epoch 558\n",
            "Encoder decoder training done in epoch 558\n",
            "critic x loss -4.355 critic z loss -0.818 \n",
            "encoder loss 4.828 decoder loss 1.134\n",
            "\n",
            "Epoch 559\n",
            "Critic training done in epoch 559\n",
            "Encoder decoder training done in epoch 559\n",
            "critic x loss -4.350 critic z loss -0.822 \n",
            "encoder loss 4.820 decoder loss 1.130\n",
            "\n",
            "Epoch 560\n",
            "Critic training done in epoch 560\n",
            "Encoder decoder training done in epoch 560\n",
            "critic x loss -4.345 critic z loss -0.822 \n",
            "encoder loss 4.816 decoder loss 1.134\n",
            "\n",
            "Epoch 561\n",
            "Critic training done in epoch 561\n",
            "Encoder decoder training done in epoch 561\n",
            "critic x loss -4.341 critic z loss -0.819 \n",
            "encoder loss 4.818 decoder loss 1.127\n",
            "\n",
            "Epoch 562\n",
            "Critic training done in epoch 562\n",
            "Encoder decoder training done in epoch 562\n",
            "critic x loss -4.334 critic z loss -0.826 \n",
            "encoder loss 4.808 decoder loss 1.119\n",
            "\n",
            "Epoch 563\n",
            "Critic training done in epoch 563\n",
            "Encoder decoder training done in epoch 563\n",
            "critic x loss -4.326 critic z loss -0.826 \n",
            "encoder loss 4.808 decoder loss 1.130\n",
            "\n",
            "Epoch 564\n",
            "Critic training done in epoch 564\n",
            "Encoder decoder training done in epoch 564\n",
            "critic x loss -4.322 critic z loss -0.828 \n",
            "encoder loss 4.795 decoder loss 1.123\n",
            "\n",
            "Epoch 565\n",
            "Critic training done in epoch 565\n",
            "Encoder decoder training done in epoch 565\n",
            "critic x loss -4.316 critic z loss -0.826 \n",
            "encoder loss 4.780 decoder loss 1.135\n",
            "\n",
            "Epoch 566\n",
            "Critic training done in epoch 566\n",
            "Encoder decoder training done in epoch 566\n",
            "critic x loss -4.313 critic z loss -0.829 \n",
            "encoder loss 4.777 decoder loss 1.130\n",
            "\n",
            "Epoch 567\n",
            "Critic training done in epoch 567\n",
            "Encoder decoder training done in epoch 567\n",
            "critic x loss -4.305 critic z loss -0.830 \n",
            "encoder loss 4.772 decoder loss 1.133\n",
            "\n",
            "Epoch 568\n",
            "Critic training done in epoch 568\n",
            "Encoder decoder training done in epoch 568\n",
            "critic x loss -4.304 critic z loss -0.831 \n",
            "encoder loss 4.770 decoder loss 1.139\n",
            "\n",
            "Epoch 569\n",
            "Critic training done in epoch 569\n",
            "Encoder decoder training done in epoch 569\n",
            "critic x loss -4.292 critic z loss -0.835 \n",
            "encoder loss 4.760 decoder loss 1.136\n",
            "\n",
            "Epoch 570\n",
            "Critic training done in epoch 570\n",
            "Encoder decoder training done in epoch 570\n",
            "critic x loss -4.287 critic z loss -0.833 \n",
            "encoder loss 4.755 decoder loss 1.119\n",
            "\n",
            "Epoch 571\n",
            "Critic training done in epoch 571\n",
            "Encoder decoder training done in epoch 571\n",
            "critic x loss -4.282 critic z loss -0.835 \n",
            "encoder loss 4.750 decoder loss 1.128\n",
            "\n",
            "Epoch 572\n",
            "Critic training done in epoch 572\n",
            "Encoder decoder training done in epoch 572\n",
            "critic x loss -4.276 critic z loss -0.833 \n",
            "encoder loss 4.745 decoder loss 1.128\n",
            "\n",
            "Epoch 573\n",
            "Critic training done in epoch 573\n",
            "Encoder decoder training done in epoch 573\n",
            "critic x loss -4.272 critic z loss -0.837 \n",
            "encoder loss 4.736 decoder loss 1.131\n",
            "\n",
            "Epoch 574\n",
            "Critic training done in epoch 574\n",
            "Encoder decoder training done in epoch 574\n",
            "critic x loss -4.263 critic z loss -0.836 \n",
            "encoder loss 4.739 decoder loss 1.147\n",
            "\n",
            "Epoch 575\n",
            "Critic training done in epoch 575\n",
            "Encoder decoder training done in epoch 575\n",
            "critic x loss -4.256 critic z loss -0.838 \n",
            "encoder loss 4.729 decoder loss 1.135\n",
            "\n",
            "Epoch 576\n",
            "Critic training done in epoch 576\n",
            "Encoder decoder training done in epoch 576\n",
            "critic x loss -4.252 critic z loss -0.838 \n",
            "encoder loss 4.715 decoder loss 1.134\n",
            "\n",
            "Epoch 577\n",
            "Critic training done in epoch 577\n",
            "Encoder decoder training done in epoch 577\n",
            "critic x loss -4.246 critic z loss -0.839 \n",
            "encoder loss 4.714 decoder loss 1.144\n",
            "\n",
            "Epoch 578\n",
            "Critic training done in epoch 578\n",
            "Encoder decoder training done in epoch 578\n",
            "critic x loss -4.239 critic z loss -0.843 \n",
            "encoder loss 4.710 decoder loss 1.139\n",
            "\n",
            "Epoch 579\n",
            "Critic training done in epoch 579\n",
            "Encoder decoder training done in epoch 579\n",
            "critic x loss -4.230 critic z loss -0.837 \n",
            "encoder loss 4.701 decoder loss 1.139\n",
            "\n",
            "Epoch 580\n",
            "Critic training done in epoch 580\n",
            "Encoder decoder training done in epoch 580\n",
            "critic x loss -4.223 critic z loss -0.845 \n",
            "encoder loss 4.690 decoder loss 1.145\n",
            "\n",
            "Epoch 581\n",
            "Critic training done in epoch 581\n",
            "Encoder decoder training done in epoch 581\n",
            "critic x loss -4.217 critic z loss -0.846 \n",
            "encoder loss 4.691 decoder loss 1.138\n",
            "\n",
            "Epoch 582\n",
            "Critic training done in epoch 582\n",
            "Encoder decoder training done in epoch 582\n",
            "critic x loss -4.212 critic z loss -0.843 \n",
            "encoder loss 4.679 decoder loss 1.143\n",
            "\n",
            "Epoch 583\n",
            "Critic training done in epoch 583\n",
            "Encoder decoder training done in epoch 583\n",
            "critic x loss -4.205 critic z loss -0.844 \n",
            "encoder loss 4.666 decoder loss 1.147\n",
            "\n",
            "Epoch 584\n",
            "Critic training done in epoch 584\n",
            "Encoder decoder training done in epoch 584\n",
            "critic x loss -4.197 critic z loss -0.849 \n",
            "encoder loss 4.655 decoder loss 1.145\n",
            "\n",
            "Epoch 585\n",
            "Critic training done in epoch 585\n",
            "Encoder decoder training done in epoch 585\n",
            "critic x loss -4.193 critic z loss -0.847 \n",
            "encoder loss 4.661 decoder loss 1.144\n",
            "\n",
            "Epoch 586\n",
            "Critic training done in epoch 586\n",
            "Encoder decoder training done in epoch 586\n",
            "critic x loss -4.184 critic z loss -0.844 \n",
            "encoder loss 4.655 decoder loss 1.146\n",
            "\n",
            "Epoch 587\n",
            "Critic training done in epoch 587\n",
            "Encoder decoder training done in epoch 587\n",
            "critic x loss -4.179 critic z loss -0.845 \n",
            "encoder loss 4.640 decoder loss 1.141\n",
            "\n",
            "Epoch 588\n",
            "Critic training done in epoch 588\n",
            "Encoder decoder training done in epoch 588\n",
            "critic x loss -4.169 critic z loss -0.850 \n",
            "encoder loss 4.634 decoder loss 1.147\n",
            "\n",
            "Epoch 589\n",
            "Critic training done in epoch 589\n",
            "Encoder decoder training done in epoch 589\n",
            "critic x loss -4.165 critic z loss -0.852 \n",
            "encoder loss 4.630 decoder loss 1.149\n",
            "\n",
            "Epoch 590\n",
            "Critic training done in epoch 590\n",
            "Encoder decoder training done in epoch 590\n",
            "critic x loss -4.158 critic z loss -0.852 \n",
            "encoder loss 4.615 decoder loss 1.146\n",
            "\n",
            "Epoch 591\n",
            "Critic training done in epoch 591\n",
            "Encoder decoder training done in epoch 591\n",
            "critic x loss -4.152 critic z loss -0.855 \n",
            "encoder loss 4.614 decoder loss 1.154\n",
            "\n",
            "Epoch 592\n",
            "Critic training done in epoch 592\n",
            "Encoder decoder training done in epoch 592\n",
            "critic x loss -4.141 critic z loss -0.856 \n",
            "encoder loss 4.607 decoder loss 1.154\n",
            "\n",
            "Epoch 593\n",
            "Critic training done in epoch 593\n",
            "Encoder decoder training done in epoch 593\n",
            "critic x loss -4.137 critic z loss -0.853 \n",
            "encoder loss 4.595 decoder loss 1.138\n",
            "\n",
            "Epoch 594\n",
            "Critic training done in epoch 594\n",
            "Encoder decoder training done in epoch 594\n",
            "critic x loss -4.126 critic z loss -0.855 \n",
            "encoder loss 4.593 decoder loss 1.149\n",
            "\n",
            "Epoch 595\n",
            "Critic training done in epoch 595\n",
            "Encoder decoder training done in epoch 595\n",
            "critic x loss -4.117 critic z loss -0.857 \n",
            "encoder loss 4.587 decoder loss 1.154\n",
            "\n",
            "Epoch 596\n",
            "Critic training done in epoch 596\n",
            "Encoder decoder training done in epoch 596\n",
            "critic x loss -4.109 critic z loss -0.860 \n",
            "encoder loss 4.579 decoder loss 1.162\n",
            "\n",
            "Epoch 597\n",
            "Critic training done in epoch 597\n",
            "Encoder decoder training done in epoch 597\n",
            "critic x loss -4.105 critic z loss -0.854 \n",
            "encoder loss 4.569 decoder loss 1.147\n",
            "\n",
            "Epoch 598\n",
            "Critic training done in epoch 598\n",
            "Encoder decoder training done in epoch 598\n",
            "critic x loss -4.097 critic z loss -0.858 \n",
            "encoder loss 4.556 decoder loss 1.154\n",
            "\n",
            "Epoch 599\n",
            "Critic training done in epoch 599\n",
            "Encoder decoder training done in epoch 599\n",
            "critic x loss -4.087 critic z loss -0.859 \n",
            "encoder loss 4.543 decoder loss 1.153\n",
            "\n",
            "Epoch 600\n",
            "Critic training done in epoch 600\n",
            "Encoder decoder training done in epoch 600\n",
            "critic x loss -4.080 critic z loss -0.863 \n",
            "encoder loss 4.538 decoder loss 1.155\n",
            "\n",
            "Epoch 601\n",
            "Critic training done in epoch 601\n",
            "Encoder decoder training done in epoch 601\n",
            "critic x loss -4.072 critic z loss -0.867 \n",
            "encoder loss 4.539 decoder loss 1.161\n",
            "\n",
            "Epoch 602\n",
            "Critic training done in epoch 602\n",
            "Encoder decoder training done in epoch 602\n",
            "critic x loss -4.065 critic z loss -0.865 \n",
            "encoder loss 4.531 decoder loss 1.150\n",
            "\n",
            "Epoch 603\n",
            "Critic training done in epoch 603\n",
            "Encoder decoder training done in epoch 603\n",
            "critic x loss -4.060 critic z loss -0.868 \n",
            "encoder loss 4.517 decoder loss 1.152\n",
            "\n",
            "Epoch 604\n",
            "Critic training done in epoch 604\n",
            "Encoder decoder training done in epoch 604\n",
            "critic x loss -4.049 critic z loss -0.864 \n",
            "encoder loss 4.522 decoder loss 1.156\n",
            "\n",
            "Epoch 605\n",
            "Critic training done in epoch 605\n",
            "Encoder decoder training done in epoch 605\n",
            "critic x loss -4.045 critic z loss -0.867 \n",
            "encoder loss 4.515 decoder loss 1.167\n",
            "\n",
            "Epoch 606\n",
            "Critic training done in epoch 606\n",
            "Encoder decoder training done in epoch 606\n",
            "critic x loss -4.038 critic z loss -0.869 \n",
            "encoder loss 4.492 decoder loss 1.165\n",
            "\n",
            "Epoch 607\n",
            "Critic training done in epoch 607\n",
            "Encoder decoder training done in epoch 607\n",
            "critic x loss -4.029 critic z loss -0.867 \n",
            "encoder loss 4.487 decoder loss 1.160\n",
            "\n",
            "Epoch 608\n",
            "Critic training done in epoch 608\n",
            "Encoder decoder training done in epoch 608\n",
            "critic x loss -4.019 critic z loss -0.868 \n",
            "encoder loss 4.471 decoder loss 1.159\n",
            "\n",
            "Epoch 609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QsWcULYplz_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}